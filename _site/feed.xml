<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.6.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-02-28T15:15:50+08:00</updated><id>http://localhost:4000/</id><title type="html">问道</title><subtitle>阿虎的个人博客</subtitle><author><name>Hu Wu</name></author><entry><title type="html">XGBoost 参数官方文档翻译</title><link href="http://localhost:4000/2018/02/28/xgboost_parameters/" rel="alternate" type="text/html" title="XGBoost 参数官方文档翻译" /><published>2018-02-28T00:00:00+08:00</published><updated>2018-02-28T00:00:00+08:00</updated><id>http://localhost:4000/2018/02/28/xgboost_parameters</id><content type="html" xml:base="http://localhost:4000/2018/02/28/xgboost_parameters/">&lt;p&gt;xgboost参数非常之多，打算借着翻译&lt;a href=&quot;https://github.com/dmlc/xgboost/blob/master/doc/parameter.md&quot;&gt;&lt;em&gt;官方文档&lt;/em&gt;&lt;/a&gt;理解一下xgboost的相关参数，以下是xgboost官方文档关于参数的全部翻译。&lt;/p&gt;

&lt;h1 id=&quot;xgboost-parameters&quot;&gt;XGBoost Parameters&lt;/h1&gt;
&lt;p&gt;Before running XGboost, we must set three types of parameters: general parameters, booster parameters and task parameters.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;General parameters relates to which booster we are using to do boosting, commonly tree or linear model&lt;/li&gt;
  &lt;li&gt;Booster parameters depends on which booster you have chosen&lt;/li&gt;
  &lt;li&gt;Learning Task parameters that decides on the learning scenario, for example, regression tasks may use different parameters with ranking tasks.&lt;/li&gt;
  &lt;li&gt;Command line parameters that relates to behavior of CLI version of xgboost.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;parameters-in-r-package&quot;&gt;Parameters in R Package&lt;/h2&gt;
&lt;p&gt;In R-package, you can use .(dot) to replace underscore in the parameters, for example, you can use max.depth as max_depth. The underscore parameters are also valid in R.&lt;/p&gt;

&lt;h2 id=&quot;general-parameters&quot;&gt;General Parameters&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;general Parameters 主要是用于选择booster ，一般是tree或者线性模型&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;booster [default=gbtree]
    &lt;ul&gt;
      &lt;li&gt;which booster to use, can be gbtree, gblinear or dart. gbtree and dart use tree based model while gblinear uses linear function.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;booster 默认参数gbtree&lt;/li&gt;
    &lt;li&gt;gbtree 和 dart 用于tree 模型&lt;/li&gt;
    &lt;li&gt;gblinear 用于linear 模型&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;silent [default=0]
    &lt;ul&gt;
      &lt;li&gt;0 means printing running messages, 1 means silent mode.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;silent 默认参数0&lt;/li&gt;
    &lt;li&gt;0 代表 打印运行时过程的信息&lt;/li&gt;
    &lt;li&gt;1 代表 不打印信息&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;nthread [default to maximum number of threads available if not set]
    &lt;ul&gt;
      &lt;li&gt;number of parallel threads used to run xgboost&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;nthread 默认最大线程数运行xgboost&lt;/li&gt;
    &lt;li&gt;n 为需要运行的线程数&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;num_pbuffer [set automatically by xgboost, no need to be set by user]
    &lt;ul&gt;
      &lt;li&gt;size of prediction buffer, normally set to number of training instances. The buffers are used to save the prediction results of last boosting step.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;strong&gt;num_pbuffer&lt;/strong&gt; xgboost 自动设置，无需用户自己设置（高亮的都是自己暂时不理解的）&lt;/li&gt;
    &lt;li&gt;num_pbuffer 是关于预测的缓存的大小，一般设置的是训练实例数。这个缓存用于
保存bootsting 最后一般的预测结果&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;num_feature [set automatically by xgboost, no need to be set by user]
    &lt;ul&gt;
      &lt;li&gt;feature dimension used in boosting, set to maximum dimension of the feature&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;strong&gt;num_feature&lt;/strong&gt; xgboost 自动设置，无需用户自己设置（高亮的都是自己暂时不理解的）&lt;/li&gt;
    &lt;li&gt;在boosting中使用feature的维度，会设置成feature最大的维度&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;parameters-for-tree-booster&quot;&gt;Parameters for Tree Booster&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;Tree booster 的参数&lt;/li&gt;
    &lt;li&gt;tree booster，它的表现远远胜过linear booster&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;eta [default=0.3, alias: learning_rate]
    &lt;ul&gt;
      &lt;li&gt;step size shrinkage used in update to prevents overfitting. After each boosting step, we can directly get the weights of new features. and eta actually shrinks the feature weights to make the boosting process more conservative.&lt;/li&gt;
      &lt;li&gt;range: [0,1]&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;eta 默认是0.3，和sklearn learning_rate概念一样。参数值的范围是0~1之间&lt;/li&gt;
    &lt;li&gt;为了防止过拟合，更新过程中会进行收缩步长。&lt;/li&gt;
    &lt;li&gt;在每次提升计算之后，算法会直接获得新特征的权重。&lt;/li&gt;
    &lt;li&gt;eta通过缩减特征的权重使得 提升过程(boosting process) 更加收敛(conservative)也就是说：可以提高模型的鲁棒性（robust）&lt;/li&gt;
    &lt;li&gt;典型值为0.01-0.2&lt;/li&gt;
    &lt;li&gt;每次更新树的时候，更新的部分的/之前树的部分&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;gamma [default=0, alias: min_split_loss]
    &lt;ul&gt;
      &lt;li&gt;minimum loss reduction required to make a further partition on a leaf node of the tree. The larger, the more conservative the algorithm will be.&lt;/li&gt;
      &lt;li&gt;range: [0,∞]&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;gamma 默认是0，和min_split_loss概念一样？？参数值的范围是0~∞之间&lt;/li&gt;
    &lt;li&gt;最小化loss reduction 需要进一步对于树的叶子节点进行分割。树越大，算法越收敛（conservative）&lt;/li&gt;
    &lt;li&gt;在节点分裂时，只有分裂后损失函数的值下降了，才会分裂这个节点。Gamma指定了节点分裂所需的最小损失函数下降值。&lt;/li&gt;
    &lt;li&gt;这个参数的值越大，算法越保守。这个参数的值和损失函数息息相关，所以是需要调整的&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;max_depth [default=6]
    &lt;ul&gt;
      &lt;li&gt;maximum depth of a tree, increase this value will make the model more complex / likely to be overfitting. 0 indicates no limit, limit is required for depth-wise grow policy.&lt;/li&gt;
      &lt;li&gt;range: [0,∞]&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;max_depth 默认是6，参数值的范围是0~∞之间&lt;/li&gt;
    &lt;li&gt;设置树的最大深度，值越大，越复杂，越容易过拟合。&lt;/li&gt;
    &lt;li&gt;0 代表不做限制，&lt;strong&gt;limit is required for depth-wise grow policy？？&lt;/strong&gt;&lt;/li&gt;
    &lt;li&gt;这个值也是用来避免过拟合的。max_depth越大，模型会学到更具体更局部的样本。&lt;/li&gt;
    &lt;li&gt;需要使用CV函数来进行调优。&lt;/li&gt;
    &lt;li&gt;典型值：3-10&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;min_child_weight [default=1]
    &lt;ul&gt;
      &lt;li&gt;minimum sum of instance weight (hessian) needed in a child. If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight, then the building process will give up further partitioning. In linear regression mode, this simply corresponds to minimum number of instances needed to be in each node. The larger, the more conservative the algorithm will be.&lt;/li&gt;
      &lt;li&gt;range: [0,∞]&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;min_child_weight 默认是1，参数值的范围是0~∞之间&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;孩子节点中最小的样本权重和&lt;/strong&gt;。&lt;/li&gt;
    &lt;li&gt;当在&lt;strong&gt;tree拆分&lt;/strong&gt;过程中，出现一个叶子节点的样本权重和小于min_child_weight时，则拆分结束。在线性回归模型中，这个参数在每个&lt;strong&gt;节点？？指的是什么&lt;/strong&gt;仅和所需要的最小样本数。该成熟越大算法越conservative&lt;/li&gt;
    &lt;li&gt;这个参数用于避免过拟合。当它的值较大时，可以避免模型学习到局部的特殊样本。&lt;/li&gt;
    &lt;li&gt;但是如果这个值过高，会导致欠拟合。这个参数需要使用CV来调整。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;max_delta_step [default=0]
    &lt;ul&gt;
      &lt;li&gt;Maximum delta step we allow each tree’s weight estimation to be. If the value is set to 0, it means there is no constraint. If it is set to a positive value, it can help making the update step more conservative. Usually this parameter is not needed, but it might help in logistic regression when class is extremely imbalanced. Set it to value of 1-10 might help control the update&lt;/li&gt;
      &lt;li&gt;range: [0,∞]&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;max_delta_step 默认是0，参数值的范围是0~∞之间&lt;/li&gt;
    &lt;li&gt;Maximum delta step就是我们对每棵树的权重的评估。&lt;/li&gt;
    &lt;li&gt;如果值设置为0，代表不做限制&lt;/li&gt;
    &lt;li&gt;如果值设置为正数，可以使 update step更加收敛。一般来说，这个参数不需要，但是对于逻辑回归出现的类型极端不平衡时候,会有作用。&lt;/li&gt;
    &lt;li&gt;参数设置为1-10之间控制update&lt;/li&gt;
    &lt;li&gt;这个参数一般用不到，但是你可以挖掘出来它更多的用处。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;subsample [default=1]
    &lt;ul&gt;
      &lt;li&gt;subsample ratio of the training instance. Setting it to 0.5 means that XGBoost randomly collected half of the data instances to grow trees and this will prevent overfitting.&lt;/li&gt;
      &lt;li&gt;range: (0,1]&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;subsample 默认是1，参数值的范围是0~1之间，不包括0&lt;/li&gt;
    &lt;li&gt;根据比例，设置是训练样本的子样本数据。如果设置为0.5，意味着，Xgboost随机选择训练样本的一半数据进行grow tree,这样做目的是防止过拟合。&lt;/li&gt;
    &lt;li&gt;和GBM中的subsample参数一模一样。这个参数控制对于每棵树，随机采样的比例。&lt;/li&gt;
    &lt;li&gt;减小这个参数的值，算法会更加保守，避免过拟合。但是，如果这个值设置得过小，它可能会导致欠拟合。&lt;/li&gt;
    &lt;li&gt;典型值：0.5-1&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;colsample_bytree [default=1]
    &lt;ul&gt;
      &lt;li&gt;subsample ratio of columns when constructing each tree.&lt;/li&gt;
      &lt;li&gt;range: (0,1]&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;colsample_bytree 默认是1，参数值的范围是0~1之间，不包括0&lt;/li&gt;
    &lt;li&gt;根据比例，设置是训练样本的列的比例（个人理解，算是特征比例），进行构建树&lt;/li&gt;
    &lt;li&gt;典型值：0.5-1&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;colsample_bylevel [default=1]
    &lt;ul&gt;
      &lt;li&gt;subsample ratio of columns for each split, in each level.&lt;/li&gt;
      &lt;li&gt;range: (0,1]&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;colsample_bylevel 默认是1，参数值的范围是0~1之间，不包括0&lt;/li&gt;
    &lt;li&gt;根据比例，设置是训练样本&lt;strong&gt;每个层级&lt;/strong&gt;的列的比例&lt;/li&gt;
    &lt;li&gt;我个人一般不太用这个参数，因为subsample参数和colsample_bytree参数可以起到相同的作用。但是如果感兴趣，可以挖掘这个参数更多的用处。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;lambda [default=1, alias: reg_lambda]
    &lt;ul&gt;
      &lt;li&gt;L2 regularization term on weights, increase this value will make model more conservative.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;lambda 默认是1，和&lt;strong&gt;reg_lambda&lt;/strong&gt;概念一样(和Ridge regression类似)&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;L2 正则术语（L2惩罚系数？？）&lt;/strong&gt;，增加该值会让模型更加收敛&lt;/li&gt;
    &lt;li&gt;这个参数是用来控制XGBoost的正则化部分的。虽然大部分数据科学家很少用到这个参数，但是这个参数在减少过拟合上还是可以挖掘出更多用处的。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;alpha [default=0, alias: reg_alpha]
    &lt;ul&gt;
      &lt;li&gt;L1 regularization term on weights, increase this value will make model more conservative.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;alpha 默认是0，和&lt;strong&gt;reg_alpha&lt;/strong&gt;概念一样(和Lasso regression类似)&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;L1 正则术语（L1惩罚系数？？）&lt;/strong&gt;，增加该值会让模型更加收敛&lt;/li&gt;
    &lt;li&gt;可以应用在很高维度的情况下，使得算法的速度更快。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;tree_method, string [default=’auto’]
    &lt;ul&gt;
      &lt;li&gt;The tree construction algorithm used in XGBoost(see description in the &lt;a href=&quot;http://arxiv.org/abs/1603.02754&quot;&gt;reference paper&lt;/a&gt;)&lt;/li&gt;
      &lt;li&gt;Distributed and external memory version only support approximate algorithm.&lt;/li&gt;
      &lt;li&gt;Choices: {‘auto’, ‘exact’, ‘approx’, ‘hist’, ‘gpu_exact’, ‘gpu_hist’}
        &lt;ul&gt;
          &lt;li&gt;‘auto’: Use heuristic to choose faster one.
            &lt;ul&gt;
              &lt;li&gt;For small to medium dataset, exact greedy will be used.&lt;/li&gt;
              &lt;li&gt;For very large-dataset, approximate algorithm will be chosen.&lt;/li&gt;
              &lt;li&gt;Because old behavior is always use exact greedy in single machine,
user will get a message when approximate algorithm is chosen to notify this choice.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;‘exact’: Exact greedy algorithm.&lt;/li&gt;
          &lt;li&gt;‘approx’: Approximate greedy algorithm using sketching and histogram.&lt;/li&gt;
          &lt;li&gt;‘hist’: Fast histogram optimized approximate greedy algorithm. It uses some performance improvements such as bins caching.&lt;/li&gt;
          &lt;li&gt;‘gpu_exact’: GPU implementation of exact algorithm.&lt;/li&gt;
          &lt;li&gt;‘gpu_hist’: GPU implementation of hist algorithm.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;tree_method, 参数是string类型，默认’auto‘，&lt;/li&gt;
    &lt;li&gt;主要用于构建树的算法（&lt;a href=&quot;http://arxiv.org/abs/1603.02754&quot;&gt;参考论文&lt;/a&gt;)&lt;/li&gt;
    &lt;li&gt;参数可以选择{‘auto’, ‘exact’, ‘approx’, ‘hist’, ‘gpu_exact’, ‘gpu_hist’}&lt;/li&gt;
    &lt;li&gt;’auto‘：用于启发式，选择更快的方式
      &lt;ul&gt;
        &lt;li&gt;数据量小型和中型的，会自动使用’exact‘模式&lt;/li&gt;
        &lt;li&gt;数据量特别大的话，会自动使用’approx‘模型&lt;/li&gt;
        &lt;li&gt;由于之前一直在单元的机器学习里都是使用’exact‘模式，所以如果自动选择’approx‘模式会有提示&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;’exact‘：纯贪婪算法&lt;/li&gt;
    &lt;li&gt;’approx‘：近似贪婪算法，使用&lt;strong&gt;sketching and histogram&lt;/strong&gt;方法&lt;/li&gt;
    &lt;li&gt;’hist’快速histogram 优化后的近似贪婪算法。用在性能的提高上，例如&lt;strong&gt;“bins caching”&lt;/strong&gt;&lt;/li&gt;
    &lt;li&gt;‘gpu_exact’： 用GPU实施exact 算法&lt;/li&gt;
    &lt;li&gt;‘gpu_hist’：用GPU实施hist 算法&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;sketch_eps, [default=0.03]
    &lt;ul&gt;
      &lt;li&gt;This is only used for approximate greedy algorithm.&lt;/li&gt;
      &lt;li&gt;This roughly translated into &lt;code class=&quot;highlighter-rouge&quot;&gt;O(1 / sketch_eps)&lt;/code&gt; number of bins.
Compared to directly select number of bins, this comes with theoretical guarantee with sketch accuracy.&lt;/li&gt;
      &lt;li&gt;Usually user does not have to tune this.
but consider setting to a lower number for more accurate enumeration.&lt;/li&gt;
      &lt;li&gt;range: (0, 1)&lt;/li&gt;
    &lt;/ul&gt;

    &lt;blockquote&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;sketch_eps&lt;/strong&gt;：默认0.03，范围是0~1，不包括0和1&lt;/li&gt;
        &lt;li&gt;本参数只能用在近似贪婪算法上&lt;/li&gt;
        &lt;li&gt;比较粗的转成0和1&lt;/li&gt;
        &lt;li&gt;一般，用户不需要关注这个参数。&lt;/li&gt;
        &lt;li&gt;总体而言，参数值越低，越能得到准确的值&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;scale_pos_weight, [default=1]
    &lt;ul&gt;
      &lt;li&gt;Control the balance of positive and negative weights, useful for unbalanced classes. A typical value to consider: sum(negative  cases) / sum(positive cases) See &lt;a href=&quot;how_to/param_tuning.md&quot;&gt;Parameters Tuning&lt;/a&gt; for more discussion. Also see Higgs Kaggle competition demo for examples: &lt;a href=&quot;../demo/kaggle-higgs/higgs-train.R&quot;&gt;R&lt;/a&gt;, &lt;a href=&quot;../demo/kaggle-higgs/higgs-numpy.py&quot;&gt;py1&lt;/a&gt;, &lt;a href=&quot;../demo/kaggle-higgs/higgs-cv.py&quot;&gt;py2&lt;/a&gt;, &lt;a href=&quot;../demo/guide-python/cross_validation.py&quot;&gt;py3&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;blockquote&gt;
      &lt;ul&gt;
        &lt;li&gt;scale_pos_weight：默认1&lt;/li&gt;
        &lt;li&gt;本参数主要控制正数和负数的权重，用在对于正负不平衡的类型的数据上。一般值为
负例样本总数/正例样本总数&lt;/li&gt;
        &lt;li&gt;可以参考&lt;a href=&quot;http://xgboost.readthedocs.io/en/latest/how_to/param_tuning.html&quot;&gt;Parameters Tuning&lt;/a&gt;有更多讨论&lt;/li&gt;
        &lt;li&gt;也可以参考Kaggle比赛demo样例
&lt;a href=&quot;https://github.com/dmlc/xgboost/blob/master/demo/kaggle-higgs/higgs-numpy.py&quot;&gt;py1&lt;/a&gt;
&lt;a href=&quot;https://github.com/dmlc/xgboost/blob/master/demo/kaggle-higgs/higgs-cv.py&quot;&gt;py2&lt;/a&gt;, &lt;a href=&quot;https://github.com/dmlc/xgboost/blob/master/demo/guide-python/cross_validation.py&quot;&gt;py3&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;总体而言，参数值越低，越能得到准确的值&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;updater, [default=’grow_colmaker,prune’]
    &lt;ul&gt;
      &lt;li&gt;A comma separated string defining the sequence of tree updaters to run, providing a modular way to construct and to modify the trees. This is an advanced parameter that is usually set automatically, depending on some other parameters. However, it could be also set explicitly by a user. The following updater plugins exist:
        &lt;ul&gt;
          &lt;li&gt;‘grow_colmaker’: non-distributed column-based construction of trees.&lt;/li&gt;
          &lt;li&gt;‘distcol’: distributed tree construction with column-based data splitting mode.&lt;/li&gt;
          &lt;li&gt;‘grow_histmaker’: distributed tree construction with row-based data splitting based on global proposal of histogram counting.&lt;/li&gt;
          &lt;li&gt;‘grow_local_histmaker’: based on local histogram counting.&lt;/li&gt;
          &lt;li&gt;‘grow_skmaker’: uses the approximate sketching algorithm.&lt;/li&gt;
          &lt;li&gt;‘sync’: synchronizes trees in all distributed nodes.&lt;/li&gt;
          &lt;li&gt;‘refresh’: refreshes tree’s statistics and/or leaf values based on the current data. Note that no random subsampling of data rows is performed.&lt;/li&gt;
          &lt;li&gt;‘prune’: prunes the splits where loss &amp;lt; min_split_loss (or gamma).&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;In a distributed setting, the implicit updater sequence value would be adjusted as follows:
        &lt;ul&gt;
          &lt;li&gt;‘grow_histmaker,prune’ when  dsplit=’row’ (or default) and prob_buffer_row == 1 (or default); or when data has multiple sparse pages&lt;/li&gt;
          &lt;li&gt;‘grow_histmaker,refresh,prune’ when  dsplit=’row’ and prob_buffer_row &amp;lt; 1&lt;/li&gt;
          &lt;li&gt;‘distcol’ when dsplit=’col’&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;strong&gt;updater&lt;/strong&gt;：默认’grow_colmaker,prune’,通过构造tree 列表可以tree之间可用逗号(,)进行分开,这种tree 列表方式可以构建和修改trees&lt;/li&gt;
    &lt;li&gt;这种高级参数，依赖其他的参数，一般设置为自动化。&lt;/li&gt;
    &lt;li&gt;当然用户也可以明确指明所使用的updater 插件&lt;/li&gt;
    &lt;li&gt;‘grow_colmaker’:基于列进行构建 非分布式tree&lt;/li&gt;
    &lt;li&gt;‘distcol’:基于列的数据的分割构建分布式tree&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;‘grow_histmaker’&lt;/strong&gt;：基于行的数据分割构建分布式tree，行数据的分割是根据gloabl histogram 统计后的建议&lt;/li&gt;
    &lt;li&gt;‘grow_local_histmaker’：基于local histogram统计后的建议构建树。&lt;/li&gt;
    &lt;li&gt;‘grow_skmaker’:使用近似sketching算法构建树&lt;/li&gt;
    &lt;li&gt;‘sync’：在所有分布式节点同步树&lt;/li&gt;
    &lt;li&gt;‘refresh’:基于目的数据，刷新树的统计和叶子的值。注意非随机的子样本数据的行将被执行&lt;/li&gt;
    &lt;li&gt;‘prune’:去掉loss 小于min_split_loss (or gamma)的分支(splits)&lt;/li&gt;
    &lt;li&gt;在分布式设置里，updater的内在序列值可以这样调整：&lt;/li&gt;
    &lt;li&gt;当数据具有非常多的稀疏页或者dsplit=’row’ (or default) 且 prob_buffer_row == 1 (or default)的时候，参数可以是’grow_histmaker,prune’&lt;/li&gt;
    &lt;li&gt;当dsplit=’row’ 且 prob_buffer_row &amp;lt; 1时，参数可以是’grow_histmaker,refresh,prune’&lt;/li&gt;
    &lt;li&gt;当dsplit=’col’，参数可以为’distcol’&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;refresh_leaf, [default=1]
    &lt;ul&gt;
      &lt;li&gt;This is a parameter of the ‘refresh’ updater plugin. When this flag is true, tree leafs as well as tree nodes’ stats are updated. When it is false, only node stats are updated.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;refresh_leaf：默认值为1&lt;/li&gt;
    &lt;li&gt;这是updater参数为’refresh’的一个插件&lt;/li&gt;
    &lt;li&gt;当值为1，树的叶子和节点值都更新&lt;/li&gt;
    &lt;li&gt;当值为0，只更新节点&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;process_type, [default=’default’]
    &lt;ul&gt;
      &lt;li&gt;A type of boosting process to run.&lt;/li&gt;
      &lt;li&gt;Choices: {‘default’, ‘update’}
        &lt;ul&gt;
          &lt;li&gt;‘default’: the normal boosting process which creates new trees.&lt;/li&gt;
          &lt;li&gt;‘update’: starts from an existing model and only updates its trees. In each boosting iteration, a tree from the initial model is taken, a specified sequence of updater plugins is run for that tree, and a modified tree is added to the new model. The new model would have either the same or smaller number of trees, depending on the number of boosting iteratons performed. Currently, the following built-in updater plugins could be meaningfully used with this process type: ‘refresh’, ‘prune’. With ‘update’, one cannot use updater plugins that create new nrees.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;process_type：默认值为’default’&lt;/li&gt;
    &lt;li&gt;参数是提高&lt;strong&gt;process&lt;/strong&gt; 的一种方式&lt;/li&gt;
    &lt;li&gt;参数有两个可选值{‘default’, ‘update’}&lt;/li&gt;
    &lt;li&gt;‘default’：标准提高process 方式，通过创建新的树&lt;/li&gt;
    &lt;li&gt;‘update’：从一个已有的模型里开始，只更新该模型的树。在每个提高的运算中，最开始的模型的树，被updater 插件的序列值（参考updater参数说明）运行最初的tree，这样经过修改过的tree，放入新的模型中。新的模型拥有tree的数目和之前比有可能相同或者比之前要小，取决于boosting iteratons的有多少数量被执行。目前，updater的参数是’refresh’, ‘prune’使用’update’参数非常有用。updater 插件不产生新trees&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;grow_policy, string [default=’depthwise’]
    &lt;ul&gt;
      &lt;li&gt;Controls a way new nodes are added to the tree.&lt;/li&gt;
      &lt;li&gt;Currently supported only if &lt;code class=&quot;highlighter-rouge&quot;&gt;tree_method&lt;/code&gt; is set to ‘hist’.&lt;/li&gt;
      &lt;li&gt;Choices: {‘depthwise’, ‘lossguide’}
        &lt;ul&gt;
          &lt;li&gt;‘depthwise’: split at nodes closest to the root.&lt;/li&gt;
          &lt;li&gt;‘lossguide’: split at nodes with highest loss change.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;grow_policy：默认值为’depthwise’&lt;/li&gt;
    &lt;li&gt;该参数是一种在树上添加新节点的方式&lt;/li&gt;
    &lt;li&gt;只有&lt;code class=&quot;highlighter-rouge&quot;&gt;tree_method&lt;/code&gt; 的参数是’hist’的时候才有用&lt;/li&gt;
    &lt;li&gt;两个参数值：’depthwise’, ‘lossguide’
      &lt;ul&gt;
        &lt;li&gt;‘depthwise’: 拆分出距离根节点最近的节点.&lt;/li&gt;
        &lt;li&gt;‘lossguide’: 拆分出loss 变化最大的节点.&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;max_leaves, [default=0]
    &lt;ul&gt;
      &lt;li&gt;Maximum number of nodes to be added. Only relevant for the ‘lossguide’ grow policy.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;max_leaves：默认值为 0&lt;/li&gt;
    &lt;li&gt;添加最大的节点数，只有grow policy设置为’lossguide’才有用&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;max_bin, [default=256]
    &lt;ul&gt;
      &lt;li&gt;This is only used if ‘hist’ is specified as &lt;code class=&quot;highlighter-rouge&quot;&gt;tree_method&lt;/code&gt;.&lt;/li&gt;
      &lt;li&gt;Maximum number of discrete bins to bucket continuous features.&lt;/li&gt;
      &lt;li&gt;Increasing this number improves the optimality of splits at the cost of higher computation time.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;strong&gt;max_bin&lt;/strong&gt;：默认值为 256&lt;/li&gt;
    &lt;li&gt;只有’tree_method‘的参数是’hist’ 才有用&lt;/li&gt;
    &lt;li&gt;该参数是对于连续特征的最大数量的分割箱&lt;/li&gt;
    &lt;li&gt;增加数量可以提高splits的优化性，代价是需要更多的运算时间&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;predictor, [default=’cpu_predictor’]
    &lt;ul&gt;
      &lt;li&gt;The type of predictor algorithm to use. Provides the same results but allows the use of GPU or CPU.
        &lt;ul&gt;
          &lt;li&gt;‘cpu_predictor’: Multicore CPU prediction algorithm.&lt;/li&gt;
          &lt;li&gt;‘gpu_predictor’: Prediction using GPU. Default for ‘gpu_exact’ and ‘gpu_hist’ tree method.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;predictor：默认值为 ‘cpu_predictor’&lt;/li&gt;
    &lt;li&gt;选择GPU还是CPU计算的预测器，当然最终结果是一样的&lt;/li&gt;
    &lt;li&gt;‘cpu_predictor’:多核CPU预测算法&lt;/li&gt;
    &lt;li&gt;‘gpu_predictor’:用GPU预测,默认’gpu_exact’ 和 ‘gpu_hist’ 的tree method&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;additional-parameters-for-dart-booster&quot;&gt;Additional parameters for Dart Booster&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;Dart Booster 额外的一些参数&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;sample_type [default=”uniform”]
    &lt;ul&gt;
      &lt;li&gt;type of sampling algorithm.
        &lt;ul&gt;
          &lt;li&gt;“uniform”: dropped trees are selected uniformly.&lt;/li&gt;
          &lt;li&gt;“weighted”: dropped trees are selected in proportion to weight.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;sample_type：默认值为 “uniform”&lt;/li&gt;
    &lt;li&gt;参数是一种取sampling 的算法&lt;/li&gt;
    &lt;li&gt;“uniform”: 均匀的去掉trees.&lt;/li&gt;
    &lt;li&gt;“weighted”: 按照一定的权重去掉trees.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;normalize_type [default=”tree”]
    &lt;ul&gt;
      &lt;li&gt;type of normalization algorithm.
        &lt;ul&gt;
          &lt;li&gt;“tree”: new trees have the same weight of each of dropped trees.
            &lt;ul&gt;
              &lt;li&gt;weight of new trees are 1 / (k + learning_rate)&lt;/li&gt;
              &lt;li&gt;dropped trees are scaled by a factor of k / (k + learning_rate)&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;“forest”: new trees have the same weight of sum of dropped trees (forest).
            &lt;ul&gt;
              &lt;li&gt;weight of new trees are 1 / (1 + learning_rate)&lt;/li&gt;
              &lt;li&gt;dropped trees are scaled by a factor of 1 / (1 + learning_rate)&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;normalize_type：默认值为 “tree”&lt;/li&gt;
    &lt;li&gt;参数是一种标准化的算法，个人觉得k应该是指dropped掉的trees的数量&lt;/li&gt;
    &lt;li&gt;“tree”:新trees和dropped掉的每颗tree有相同的权重&lt;/li&gt;
    &lt;li&gt;新trees的权重是1 / (k + learning_rate)&lt;/li&gt;
    &lt;li&gt;dropped掉的 trees 按照  k / (k + learning_rate)缩放&lt;/li&gt;
    &lt;li&gt;“forest”: 新trees和drop掉的数目的总和有相同的权重
      &lt;ul&gt;
        &lt;li&gt;新trees 的权重1 / (1 + learning_rate)&lt;/li&gt;
        &lt;li&gt;dropped掉的 trees 按照  1 / (1 + learning_rate)的权重缩放&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;rate_drop [default=0.0]
    &lt;ul&gt;
      &lt;li&gt;dropout rate (a fraction of previous trees to drop during the dropout).&lt;/li&gt;
      &lt;li&gt;range: [0.0, 1.0]&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;rate_drop：默认值为 0，值的范围[0.0~1.0]&lt;/li&gt;
    &lt;li&gt;dropout的比例（就是对于之前的tree，drop掉的比例）&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;one_drop [default=0]
    &lt;ul&gt;
      &lt;li&gt;when this flag is enabled, at least one tree is always dropped during the dropout (allows Binomial-plus-one or epsilon-dropout from the original DART paper).&lt;/li&gt;
    &lt;/ul&gt;

    &lt;blockquote&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;one_drop&lt;/strong&gt;：默认值为 0&lt;/li&gt;
        &lt;li&gt;如果值为1，至少有一个tree，在dropout期间总会被去掉的&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;skip_drop [default=0.0]
    &lt;ul&gt;
      &lt;li&gt;Probability of skipping the dropout procedure during a boosting iteration.
        &lt;ul&gt;
          &lt;li&gt;If a dropout is skipped, new trees are added in the same manner as gbtree.&lt;/li&gt;
          &lt;li&gt;Note that non-zero skip_drop has higher priority than rate_drop or one_drop.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;range: [0.0, 1.0]&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;skip_drop：默认值为 0.0，参数值范围[0.0~1.0]&lt;/li&gt;
    &lt;li&gt;在提升迭代期间，跳过丢弃过程的概率&lt;/li&gt;
    &lt;li&gt;如果一个dropout 被跳过，新trees 将会和gbtree一样的形式增加上&lt;/li&gt;
    &lt;li&gt;注意，非0 skip_drop 比 rate_drop or one_drop有更高有限权&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;parameters-for-linear-booster&quot;&gt;Parameters for Linear Booster&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;线性bootser&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;lambda [default=0, alias: reg_lambda]
    &lt;ul&gt;
      &lt;li&gt;L2 regularization term on weights, increase this value will make model more conservative.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;lambda 默认是0，和&lt;strong&gt;reg_lambda&lt;/strong&gt;概念一样&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;L2 正则术语（L2惩罚系数？？）&lt;/strong&gt;，增加该值会让模型更加收敛&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;alpha [default=0, alias: reg_alpha]
    &lt;ul&gt;
      &lt;li&gt;L1 regularization term on weights, increase this value will make model more conservative.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;alpha 默认是0，和&lt;strong&gt;reg_alpha&lt;/strong&gt;概念一样&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;L1 正则术语（L1惩罚系数？？）&lt;/strong&gt;，增加该值会让模型更加收敛&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;lambda_bias [default=0, alias: reg_lambda_bias]
    &lt;ul&gt;
      &lt;li&gt;L2 regularization term on bias (no L1 reg on bias because it is not important)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;lambda_bias 默认是0，和&lt;strong&gt;reg_lambda_bias&lt;/strong&gt;概念一样&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;在偏置上的L2 正则&lt;/strong&gt;，在L1上没有偏置项的正则，因为L1时偏置不重要&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;parameters-for-tweedie-regression&quot;&gt;Parameters for Tweedie Regression&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Tweedie_distribution&quot;&gt;Tweedie 分布&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;tweedie_variance_power [default=1.5]
    &lt;ul&gt;
      &lt;li&gt;parameter that controls the variance of the Tweedie distribution
        &lt;ul&gt;
          &lt;li&gt;var(y) ~ E(y)^tweedie_variance_power&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;range: (1,2)&lt;/li&gt;
      &lt;li&gt;set closer to 2 to shift towards a gamma distribution&lt;/li&gt;
      &lt;li&gt;set closer to 1 to shift towards a Poisson distribution.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;tweedie_variance_power 默认值为1.5，范围(1~2)&lt;/li&gt;
    &lt;li&gt;参数变量控制Tweedie 分布
      &lt;ul&gt;
        &lt;li&gt;var(y) ~ E(y)^tweedie_variance_power&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;参数值离2越靠近，该分布越接近gamma分布&lt;/li&gt;
    &lt;li&gt;参数值离1越靠近，该分布越接近泊松分布&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;learning-task-parameters&quot;&gt;Learning Task Parameters&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;学习任务参数&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;Specify the learning task and the corresponding learning objective. The objective options are below:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;指定学习任务和学习目标。学习目标如下：&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;objective [default=reg:linear]
    &lt;ul&gt;
      &lt;li&gt;“reg:linear” –linear regression&lt;/li&gt;
      &lt;li&gt;“reg:logistic” –logistic regression&lt;/li&gt;
      &lt;li&gt;“binary:logistic” –logistic regression for binary classification, output probability&lt;/li&gt;
      &lt;li&gt;“binary:logitraw” –logistic regression for binary classification, output score before logistic transformation&lt;/li&gt;
      &lt;li&gt;“gpu:reg:linear”, “gpu:reg:logistic”, “gpu:binary:logistic”, gpu:binary:logitraw” –versions
of the corresponding objective functions evaluated on the GPU; note that like the GPU histogram algorithm,
they can only be used when the entire training session uses the same dataset&lt;/li&gt;
      &lt;li&gt;“count:poisson” –poisson regression for count data, output mean of poisson distribution
        &lt;ul&gt;
          &lt;li&gt;max_delta_step is set to 0.7 by default in poisson regression (used to safeguard optimization)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;“multi:softmax” –set XGBoost to do multiclass classification using the softmax objective, you also need to set num_class(number of classes)&lt;/li&gt;
      &lt;li&gt;“multi:softprob” –same as softmax, but output a vector of ndata * nclass, which can be further reshaped to ndata, nclass matrix. The result contains predicted probability of each data point belonging to each class.&lt;/li&gt;
      &lt;li&gt;“rank:pairwise” –set XGBoost to do ranking task by minimizing the pairwise loss&lt;/li&gt;
      &lt;li&gt;“reg:gamma” –gamma regression with log-link. Output is a mean of gamma distribution. It might be useful, e.g., for modeling insurance claims severity, or for any outcome that might be &lt;a href=&quot;https://en.wikipedia.org/wiki/Gamma_distribution#Applications&quot;&gt;gamma-distributed&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;“reg:tweedie” –Tweedie regression with log-link. It might be useful, e.g., for modeling total loss in insurance, or for any outcome that might be &lt;a href=&quot;https://en.wikipedia.org/wiki/Tweedie_distribution#Applications&quot;&gt;Tweedie-distributed&lt;/a&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;objective,默认值是reg:linear&lt;/li&gt;
    &lt;li&gt;“reg:linear” ：线性回归&lt;/li&gt;
    &lt;li&gt;“reg:logistic”：逻辑回归&lt;/li&gt;
    &lt;li&gt;“binary:logistic”：二分类逻辑回归，输出概率&lt;/li&gt;
    &lt;li&gt;“binary:logitraw”：二分类逻辑回归，输出是逻辑为0/1的前一步的分数&lt;/li&gt;
    &lt;li&gt;“gpu:reg:linear”, “gpu:reg:logistic”, “gpu:binary:logistic”：用GPU跑对应的回归，请注意，像GPU直方图算法一样，在整个训练过程中只能用相同的dataset&lt;/li&gt;
    &lt;li&gt;count:poisson”：计数问题的泊松回归，输出为泊松分布的平均值
      &lt;ul&gt;
        &lt;li&gt;在泊松分布中，max_delta_step参数值默认为0.7（用于维护优化）&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;“multi:softmax”：用于Xgboost 做多分类问题，需要设置num_class（分类的个数）&lt;/li&gt;
    &lt;li&gt;“multi:softprob”：和softmax一样，只是输出的是一个向量（vector）ndata*nclass，进一步可以reshape成ndata，nclass的矩阵。结果就是包含每个数据属于每一类的概率&lt;/li&gt;
    &lt;li&gt;“rank:pairwise”：让Xgboost 做排名任务，通过最小化&lt;a href=&quot;https://en.wikipedia.org/wiki/Learning_to_rank#Pairwise_approach&quot;&gt;&lt;strong&gt;pairwise loss&lt;/strong&gt;&lt;/a&gt;(Learn to rank的一种方法)&lt;/li&gt;
    &lt;li&gt;“reg:gamma”：gamma回归带有&lt;strong&gt;日志链接（log-link）？？&lt;/strong&gt; 。输出gamma分布的均值。对于 保险索赔严重性建模 或者是任何符合&lt;a href=&quot;(https://en.wikipedia.org/wiki/Gamma_distribution#Applications)&quot;&gt;gamma分布&lt;/a&gt;输出 可能是有用&lt;/li&gt;
    &lt;li&gt;“reg:tweedie”：Tweedie回归带有&lt;strong&gt;日志链接（log-link）？？&lt;/strong&gt; . 对于 保险中的全部损失进行建模建模 或者是任何符合&lt;a href=&quot;https://en.wikipedia.org/wiki/Tweedie_distribution#Applications&quot;&gt;tweedie分布&lt;/a&gt;)输出 可能是有用。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;base_score [default=0.5]
    &lt;ul&gt;
      &lt;li&gt;the initial prediction score of all instances, global bias&lt;/li&gt;
      &lt;li&gt;for sufficient number of iterations, changing this value will not have too much effect.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;base_score,默认值为0.5&lt;/li&gt;
    &lt;li&gt;所有实例的初始预测分数，全局偏置&lt;/li&gt;
    &lt;li&gt;有足够的迭代次数，改变该值并没有多少影响&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;eval_metric [default according to objective]
    &lt;ul&gt;
      &lt;li&gt;evaluation metrics for validation data, a default metric will be assigned according to objective (rmse for regression, and error for classification, mean average precision for ranking )&lt;/li&gt;
      &lt;li&gt;User can add multiple evaluation metrics, for python user, remember to pass the metrics in as list of parameters pairs instead of map, so that latter ‘eval_metric’ won’t override previous one&lt;/li&gt;
      &lt;li&gt;The choices are listed below:
        &lt;ul&gt;
          &lt;li&gt;“rmse”: &lt;a href=&quot;http://en.wikipedia.org/wiki/Root_mean_square_error&quot;&gt;root mean square error&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;“mae”: &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_absolute_error&quot;&gt;mean absolute error&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;“logloss”: negative &lt;a href=&quot;http://en.wikipedia.org/wiki/Log-likelihood&quot;&gt;log-likelihood&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;“error”: Binary classification error rate. It is calculated as #(wrong cases)/#(all cases). For the predictions, the evaluation will regard the instances with prediction value larger than 0.5 as positive instances, and the others as negative instances.&lt;/li&gt;
          &lt;li&gt;“error@t”: a different than 0.5 binary classification threshold value could be specified by providing a numerical value through ‘t’.&lt;/li&gt;
          &lt;li&gt;“merror”: Multiclass classification error rate. It is calculated as #(wrong cases)/#(all cases).&lt;/li&gt;
          &lt;li&gt;“mlogloss”: &lt;a href=&quot;https://www.kaggle.com/wiki/LogLoss&quot;&gt;Multiclass logloss&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;“auc”: &lt;a href=&quot;http://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_curve&quot;&gt;Area under the curve&lt;/a&gt; for ranking evaluation.&lt;/li&gt;
          &lt;li&gt;“ndcg”:&lt;a href=&quot;http://en.wikipedia.org/wiki/NDCG&quot;&gt;Normalized Discounted Cumulative Gain&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;“map”:&lt;a href=&quot;http://en.wikipedia.org/wiki/Mean_average_precision#Mean_average_precision&quot;&gt;Mean average precision&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;“ndcg@n”,”map@n”: n can be assigned as an integer to cut off the top positions in the lists for evaluation.&lt;/li&gt;
          &lt;li&gt;“ndcg-“,”map-“,”ndcg@n-“,”map@n-“: In XGBoost, NDCG and MAP will evaluate the score of a list without any positive samples as 1. By adding “-“ in the evaluation metric XGBoost will evaluate these score as 0 to be consistent under some conditions.training repeatedly&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;“poisson-nloglik”: negative log-likelihood for Poisson regression&lt;/li&gt;
      &lt;li&gt;“gamma-nloglik”: negative log-likelihood for gamma regression&lt;/li&gt;
      &lt;li&gt;“gamma-deviance”: residual deviance for gamma regression&lt;/li&gt;
      &lt;li&gt;“tweedie-nloglik”: negative log-likelihood for Tweedie regression (at a specified value of the tweedie_variance_power parameter)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;eval_metric:默认值取决于目标&lt;/li&gt;
    &lt;li&gt;对于验证集的评估指标。默认指标根据目标的不同有所不同（回归问题指标：rmse，分类问题：error，排序问题：mean）&lt;/li&gt;
    &lt;li&gt;用户可以添加多个评估指标。对于Python用户要以list传递参数对给程序，而不是map，这样后一个指标就不会覆盖前一个&lt;/li&gt;
    &lt;li&gt;参数列表如下：&lt;/li&gt;
    &lt;li&gt;’rmse’&lt;a href=&quot;http://en.wikipedia.org/wiki/Root_mean_square_error&quot;&gt;root mean square error&lt;/a&gt;剩余标准差(均方根误差)&lt;/li&gt;
    &lt;li&gt;“mae”: &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_absolute_error&quot;&gt;mean absolute error&lt;/a&gt;平均绝对误差&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;“logloss”&lt;/strong&gt;: negative 负对数似然函数值 &lt;a href=&quot;http://en.wikipedia.org/wiki/Log-likelihood&quot;&gt;log-likelihood&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;”error”：二分类错误率，计算公式（错误cases）/（全部cases），评估中，对于预测值大于0.5位正例，剩下为负例&lt;/li&gt;
    &lt;li&gt;“error@t”：二分类错误率，通过t指定阈值，而非0.5，超过阈值为正例，其余为负例&lt;/li&gt;
    &lt;li&gt;“merror”：多分类错误率。计算公式：（错误cases）/（全部cases）&lt;/li&gt;
    &lt;li&gt;“mlogloss”: &lt;a href=&quot;https://www.kaggle.com/wiki/LogLoss&quot;&gt;Multiclass logloss&lt;/a&gt;多分类logloass&lt;/li&gt;
    &lt;li&gt;“&lt;strong&gt;auc&lt;/strong&gt;”: &lt;a href=&quot;http://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_curve&quot;&gt;Area under the curve&lt;/a&gt; for ranking evaluation.曲线下面积-相关的ROC曲线&lt;/li&gt;
    &lt;li&gt;“&lt;strong&gt;ndcg”&lt;/strong&gt;:&lt;a href=&quot;http://en.wikipedia.org/wiki/NDCG&quot;&gt;Normalized Discounted Cumulative Gain&lt;/a&gt;折扣累积收益（DCG）是衡量排名质量的一个指标。属于信息检索范围（Information retrieval）&lt;/li&gt;
    &lt;li&gt;“&lt;strong&gt;map&lt;/strong&gt;”:&lt;a href=&quot;http://en.wikipedia.org/wiki/Mean_average_precision#Mean_average_precision&quot;&gt;Mean average precision&lt;/a&gt; 属于信息检索范围（Information retrieval）&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;“ndcg@n”,”map@n”&lt;/strong&gt;: 其中n为整数，在评估列表中截断顶部位置&lt;/li&gt;
    &lt;li&gt;“ndcg-“,”map-“,”ndcg@n-“,”map@n-“:在XGBoost中，NDCG和MAP将评估没有任何正面样本的列表的评分为1.通过在评估量度中添加“ - ”，XGBoost会在某些情况下评估这些评分为0，然后不断的训练&lt;/li&gt;
    &lt;li&gt;“poisson-nloglik”：泊松分布回归的负似然性&lt;/li&gt;
    &lt;li&gt;“gamma-nloglik”: gamma回归的负&lt;a href=&quot;https://en.wikipedia.org/wiki/Likelihood_function#Example:_the_gamma_distribution&quot;&gt;gamma分布似然性&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;“gamma-deviance”：γ回归的&lt;strong&gt;剩余偏差（residual deviance）&lt;/strong&gt;&lt;/li&gt;
    &lt;li&gt;“tweedie-nloglik”：Tweedie回归负向似然值&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;seed [default=0]
    &lt;ul&gt;
      &lt;li&gt;random number seed.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;seed：默认为p0&lt;/li&gt;
    &lt;li&gt;随机的number种子&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;command-line-parameters&quot;&gt;Command Line Parameters&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;命令行参数&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;The following parameters are only used in the console version of xgboost&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;use_buffer [default=1]
    &lt;ul&gt;
      &lt;li&gt;Whether to create a binary buffer from text input. Doing so normally will speed up loading times&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;num_round
    &lt;ul&gt;
      &lt;li&gt;The number of rounds for boosting&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;data
    &lt;ul&gt;
      &lt;li&gt;The path of training data&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;test:data
    &lt;ul&gt;
      &lt;li&gt;The path of test data to do prediction&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;save_period [default=0]
    &lt;ul&gt;
      &lt;li&gt;the period to save the model, setting save_period=10 means that for every 10 rounds XGBoost will save the model, setting it to 0 means not saving any model during the training.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;task [default=train] options: train, pred, eval, dump
    &lt;ul&gt;
      &lt;li&gt;train: training using data&lt;/li&gt;
      &lt;li&gt;pred: making prediction for test:data&lt;/li&gt;
      &lt;li&gt;eval: for evaluating statistics specified by eval[name]=filename&lt;/li&gt;
      &lt;li&gt;dump: for dump the learned model into text format (preliminary)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;model_in [default=NULL]
    &lt;ul&gt;
      &lt;li&gt;path to input model, needed for test, eval, dump, if it is specified in training, xgboost will continue training from the input model&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;model_out [default=NULL]
    &lt;ul&gt;
      &lt;li&gt;path to output model after training finishes, if not specified, will output like 0003.model where 0003 is number of rounds to do boosting.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;model_dir [default=models]
    &lt;ul&gt;
      &lt;li&gt;The output directory of the saved models during training&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;fmap
    &lt;ul&gt;
      &lt;li&gt;feature map, used for dump model&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;name_dump [default=dump.txt]
    &lt;ul&gt;
      &lt;li&gt;name of model dump file&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;name_pred [default=pred.txt]
    &lt;ul&gt;
      &lt;li&gt;name of prediction file, used in pred mode&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;pred_margin [default=0]
    &lt;ul&gt;
      &lt;li&gt;predict margin instead of transformed probability&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;以下参数只能用在xgboost的控制台版本&lt;/li&gt;
    &lt;li&gt;use_buffer ：默认值为1
      &lt;ul&gt;
        &lt;li&gt;是否为输入创建二进制的缓存文件，缓存文件通常可以加速加载次数&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;num_round
      &lt;ul&gt;
        &lt;li&gt;booting迭代的次数&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;data
      &lt;ul&gt;
        &lt;li&gt;训练数据的路径&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;test:data
      &lt;ul&gt;
        &lt;li&gt;测试数据的路径&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;save_period ：默认为0
      &lt;ul&gt;
        &lt;li&gt;保存模型的周期，例如save_period=10，意味着训练每10周xgboost保存一次模型，0 代表不保存模型&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;task：默认train，可以选择train, pred, eval, dump
      &lt;ul&gt;
        &lt;li&gt;train：训练使用数据&lt;/li&gt;
        &lt;li&gt;pred：对测试数据进行预测&lt;/li&gt;
        &lt;li&gt;eval：通过eval[name]=filename定义评价指标&lt;/li&gt;
        &lt;li&gt;dump：将习得的模型保存文本而是&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;model_in&lt;/strong&gt;：默认NULL
      &lt;ul&gt;
        &lt;li&gt;指向模型的路径，测试、评价、保存数据都会用到，如果指明需要训练，xgboost将接着输入的模型进行训练&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;model_out：默认NULL
      &lt;ul&gt;
        &lt;li&gt;训练结束后，输出的模型的路径，如果没有明确指明，模型输出将会是0003.model这样，0003代表boosting的第3次数训练的结果&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;model_dir ：默认models
      &lt;ul&gt;
        &lt;li&gt;模型在训练期间保存的路径&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;fmap&lt;/strong&gt;
      &lt;ul&gt;
        &lt;li&gt;特征地图，用作保存模型&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;name_dump ：默认dump.txt
      &lt;ul&gt;
        &lt;li&gt;模型的保存文件&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;name_pred：默认pred.txt
      &lt;ul&gt;
        &lt;li&gt;预测文件，用在pred 模式&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;pred_margin&lt;/strong&gt;：默认值0
      &lt;ul&gt;
        &lt;li&gt;输出预测的边界而不是转换之后的概率&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;翻译中部分参考&lt;a href=&quot;http://blog.csdn.net/han_xiaoyang/article/details/52665396&quot;&gt;XGBoost参数调优完全指南&lt;/a&gt;&lt;/p&gt;</content><author><name>Hu Wu</name></author><category term="jekyll" /><summary type="html">xgboost参数非常之多，打算借着翻译官方文档理解一下xgboost的相关参数，以下是xgboost官方文档关于参数的全部翻译。</summary></entry><entry><title type="html">XGBoost 参数调优(python)</title><link href="http://localhost:4000/2018/02/28/XGboost_param_share/" rel="alternate" type="text/html" title="XGBoost 参数调优(python)" /><published>2018-02-28T00:00:00+08:00</published><updated>2018-02-28T00:00:00+08:00</updated><id>http://localhost:4000/2018/02/28/XGboost_param_share</id><content type="html" xml:base="http://localhost:4000/2018/02/28/XGboost_param_share/">&lt;p&gt;本篇初步探索了xgboost在调参数的方法&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;背景&lt;/strong&gt;：数据科学里，首先要对数据特征的提取建模，然后用机器学习模拟预测。目前来说，工业界暂时不清楚，但是在只要涉及数据科学的比赛，机器学习模型肯定少补了Xgboost。Xgboost的参数非常繁多（50多个参数），本次主要介绍如何进行Xgboost调参&lt;/p&gt;

&lt;h2 id=&quot;调参原理&quot;&gt;调参原理：&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;1、利用sklearn的网格搜索GridSearchCV进行调试，但是GridSearchCV无法直接对xgboost进行调试&lt;/em&gt;
&lt;em&gt;2、利用xgboost的sklearn接口&lt;a href=&quot;http://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn&quot;&gt;XGBRegressor/XGBClassifier&lt;/a&gt;,利用接口，将xgboost的参数带入到GridSearchCV进行遍历调优&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;调参原则&quot;&gt;调参原则：&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;1、参数先粗调再微调&lt;/em&gt;
&lt;em&gt;2、参数先调对结果影响大的（哪些影响大，可以上网先找找）&lt;/em&gt;
&lt;em&gt;3、分批次调参&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;xgboost的参数&quot;&gt;Xgboost的参数&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;General parameters relates to which booster we are using to do boosting, commonly tree or linear model&lt;/li&gt;
  &lt;li&gt;Booster parameters depends on which booster you have chosen&lt;/li&gt;
  &lt;li&gt;Learning Task parameters that decides on the learning scenario, for example, regression tasks may use different parameters with ranking tasks.&lt;/li&gt;
  &lt;li&gt;Command line parameters that relates to behavior of CLI version of xgboost.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;调参的顺序&quot;&gt;调参的顺序：&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;1、选定一组基准参数，这些参数有经验的话，用经验值，没有经验可以用官方的默认值&lt;/em&gt;
&lt;em&gt;2 、max_depth 和 min_child_weight 参数调优&lt;/em&gt;
&lt;em&gt;3、gamma参数调优&lt;/em&gt;
&lt;em&gt;4、调整subsample 和 colsample_bytree 参数调优&lt;/em&gt;
&lt;em&gt;5、正则化参数调优（reg_alpha、reg_lambda&lt;/em&gt;
&lt;em&gt;6、降低学习率和使用更多的树（learning_rate、n_estimators）&lt;/em&gt;
&lt;em&gt;7、可以探索的参数max_delta_step 、scale_pos_weight、base_score&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;接下来让我们先导入对应的模块，且对数据进行一定的处理&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#Import libraries:&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;xgboost&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xgb&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;xgboost.sklearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;XGBRegressor&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cross_validation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;#Additional     scklearn functions&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.grid_search&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GridSearchCV&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;#Perforing grid search&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pylab&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#import warnings&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#warnings.filterwarnings('ignore')&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inline&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pylab&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'figure.figsize'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean_absolute_error&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fbeta_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_scorer&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean_squared_error&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;math&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'../../raw/LiChuan/trainSaleDate.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 去掉 2012 年数据, 噪音太多&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'year'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2012&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop_duplicates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sale_quantity&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'class_id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sale_quantity'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'sale_date'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# train_test = pd.concat([train, test]).reset_index(drop=True)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;year_dummies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_dummies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'year'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prefix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'year'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;month_dummies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_dummies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'month'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prefix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'month'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;year_dummies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month_dummies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'year'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'month'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fillna&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 获取 2017-10 数据作为测试集&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;140&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;140&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 2012-01 至 2017-10 作为训练集&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;140&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;140&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;modelfit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;useTrainCV&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv_folds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;early_stopping_rounds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;useTrainCV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;xgb_param&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_xgb_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;xgtrain&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xgb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DMatrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;xgtest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xgb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DMatrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cvresult&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xgb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xgb_param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xgtrain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_boost_round&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'n_estimators'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nfold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cv_folds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                          &lt;span class=&quot;n&quot;&gt;early_stopping_rounds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;early_stopping_rounds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show_stdv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;alg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cvresult&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;#cvresult.shape[0]和alg.get_params()['n_estimators']值一样&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;#Fit the algorithm on the data&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;alg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eval_metric&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rmse'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#Predict training set:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dtrain_predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#Print model report:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; Score (Train): &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean_squared_error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtrain_predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#Predict on testing data:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dtest_predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Score (Test): &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean_squared_error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtest_predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;1选定一组基准参数这些参数有经验的话用经验值没有经验可以用官方的默认值&quot;&gt;1、选定一组基准参数，这些参数有经验的话，用经验值，没有经验可以用官方的默认值&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;n&quot;&gt;xgb1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;XGBRegressor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;booster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'gbtree'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;objective&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'reg:linear'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;eval_metric&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rmse'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;min_child_weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;max_depth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;subsample&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;colsample_bytree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;tree_method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'exact'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;nthread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;scale_pos_weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;27&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;modelfit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xgb1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Score (Train): 8054.387826&lt;/p&gt;

&lt;p&gt;Score (Test): 27418.413465&lt;/p&gt;

&lt;h4 id=&quot;xgb1的参数&quot;&gt;xgb1的参数&lt;/h4&gt;
&lt;p&gt;base_score=0.5, booster=’gbtree’, colsample_bylevel=1,
colsample_bytree=0.8, eval_metric=’rmse’, gamma=0.1,
learning_rate=0.1, max_delta_step=0, max_depth=5,
min_child_weight=1.1, missing=None, n_estimators=400, n_jobs=1,
nthread=4, objective=’reg:linear’, random_state=0, reg_alpha=0,
reg_lambda=1, scale_pos_weight=1, seed=27, silent=True,
subsample=0.8, tree_method=’exact’&lt;/p&gt;

&lt;h4 id=&quot;2-max_depth-和-min_child_weight-参数调优&quot;&gt;2、 max_depth 和 min_child_weight 参数调优&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#Grid seach on subsample and max_features&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#Choose all predictors except target &amp;amp; IDcols&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;param_test1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'max_depth'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'min_child_weight'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gsearch1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GridSearchCV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;estimator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;XGBRegressor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;booster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'gbtree'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;objective&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'reg:linear'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;eval_metric&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rmse'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;min_child_weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;max_depth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;subsample&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;colsample_bytree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;tree_method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'exact'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;nthread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;scale_pos_weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;27&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_test1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scoring&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'mean_squared_error'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_jobs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gsearch1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;CPU times: user 8.41 s, sys: 323 ms, total: 8.73 s
Wall time: 1min 50s&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;gsearch1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid_scores_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gsearch1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_params_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gsearch1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_score_&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;([mean: -37307.30173, std: 20190.10346, params: {‘max_depth’: 3, ‘min_child_weight’: 1},
  mean: -37858.56838, std: 20117.31618, params: {‘max_depth’: 3, ‘min_child_weight’: 3},
  mean: -37074.47698, std: 18889.70050, params: {‘max_depth’: 3, ‘min_child_weight’: 5},
  mean: -33870.23259, std: 19987.57504, params: {‘max_depth’: 5, ‘min_child_weight’: 1},
  mean: -33240.71438, std: 18837.21289, params: {‘max_depth’: 5, ‘min_child_weight’: 3},
  mean: -36997.23968, std: 22463.08107, params: {‘max_depth’: 5, ‘min_child_weight’: 5},
  mean: -33965.78497, std: 18547.66643, params: {‘max_depth’: 7, ‘min_child_weight’: 1},
  mean: -34735.79444, std: 20149.70986, params: {‘max_depth’: 7, ‘min_child_weight’: 3},
  mean: -37111.82576, std: 22824.75284, params: {‘max_depth’: 7, ‘min_child_weight’: 5},
  mean: -35508.45759, std: 19274.54528, params: {‘max_depth’: 9, ‘min_child_weight’: 1},
  mean: -35914.95148, std: 20508.98895, params: {‘max_depth’: 9, ‘min_child_weight’: 3},
  mean: -36943.84821, std: 20971.33128, params: {‘max_depth’: 9, ‘min_child_weight’: 5}],
 {‘max_depth’: 5, ‘min_child_weight’: 3},
 -33240.714381367696)&lt;/p&gt;

&lt;h4 id=&quot;不放心的话尝试一下其他值&quot;&gt;不放心的话尝试一下其他值&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#Grid seach on subsample and max_features&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#Choose all predictors except target &amp;amp; IDcols&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;param_test1b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'min_child_weight'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gsearch1b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GridSearchCV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;estimator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;XGBRegressor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;booster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'gbtree'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;objective&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'reg:linear'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;eval_metric&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rmse'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;min_child_weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;max_depth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;subsample&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;colsample_bytree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;tree_method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'exact'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;nthread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;scale_pos_weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;27&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_test1b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scoring&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'mean_squared_error'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_jobs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gsearch1b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;CPU times: user 7.28 s, sys: 187 ms, total: 7.46 s
Wall time: 36.1 s&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;gsearch1b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid_scores_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gsearch1b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_params_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gsearch1b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_score_&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;([mean: -37171.16050, std: 21067.04892, params: {‘min_child_weight’: 6},
mean: -36495.04327, std: 20191.87333, params: {‘min_child_weight’: 8},
mean: -36298.35708, std: 19605.68520, params: {‘min_child_weight’: 10},
mean: -35836.89718, std: 18897.25594, params: {‘min_child_weight’: 12}],
{‘min_child_weight’: 12},
-35836.89718422033)&lt;/p&gt;

&lt;h4 id=&quot;3gamma参数调优&quot;&gt;3、gamma参数调优&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;param_test3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'gamma'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;10.0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gsearch3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GridSearchCV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;estimator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;XGBRegressor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;booster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'gbtree'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;objective&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'reg:linear'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;eval_metric&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rmse'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;min_child_weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;max_depth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;subsample&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;colsample_bytree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;tree_method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'exact'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;nthread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;scale_pos_weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;27&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_test3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scoring&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'mean_squared_error'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_jobs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gsearch3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;CPU times: user 7.82 s, sys: 227 ms, total: 8.05 s
Wall time: 48.6 s&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;gsearch3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid_scores_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gsearch3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_params_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gsearch3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_score_&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;([mean: -33240.71438, std: 18837.21289, params: {‘gamma’: 0.0},
  mean: -33240.71438, std: 18837.21289, params: {‘gamma’: 0.1},
  mean: -33240.71438, std: 18837.21289, params: {‘gamma’: 0.2},
  mean: -33240.71438, std: 18837.21289, params: {‘gamma’: 0.3},
  mean: -33240.71438, std: 18837.21289, params: {‘gamma’: 0.4}],
 {‘gamma’: 0.0},
 -33240.714381367696)&lt;/p&gt;

&lt;h4 id=&quot;4调整subsample-和-colsample_bytree-参数调优&quot;&gt;4、调整subsample 和 colsample_bytree 参数调优&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#Grid seach on subsample and max_features&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#Choose all predictors except target &amp;amp; IDcols&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;param_test4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'subsample'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;10.0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'colsample_bytree'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;10.0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gsearch4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GridSearchCV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;estimator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;XGBRegressor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;booster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'gbtree'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;objective&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'reg:linear'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;eval_metric&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rmse'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;min_child_weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;max_depth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;subsample&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;colsample_bytree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;tree_method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'exact'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;nthread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;scale_pos_weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;27&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_test4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scoring&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'mean_squared_error'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_jobs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gsearch4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;CPU times: user 9.08 s, sys: 409 ms, total: 9.49 s
Wall time: 1min 56s&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;gsearch4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid_scores_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gsearch4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_params_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gsearch4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_score_&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;([mean: -33599.72943, std: 18191.85111, params: {‘colsample_bytree’: 0.6, ‘subsample’: 0.6},
  mean: -34504.14133, std: 18332.87810, params: {‘colsample_bytree’: 0.6, ‘subsample’: 0.7},
  mean: -34742.90855, std: 20106.86473, params: {‘colsample_bytree’: 0.6, ‘subsample’: 0.8},
  mean: -34180.71176, std: 21119.88727, params: {‘colsample_bytree’: 0.6, ‘subsample’: 0.9},
  mean: -33706.05489, std: 17873.54056, params: {‘colsample_bytree’: 0.7, ‘subsample’: 0.6},
  mean: -35365.73247, std: 20734.72408, params: {‘colsample_bytree’: 0.7, ‘subsample’: 0.7},
  mean: -36003.56230, std: 20460.12605, params: {‘colsample_bytree’: 0.7, ‘subsample’: 0.8},
  mean: -35102.41564, std: 20596.99663, params: {‘colsample_bytree’: 0.7, ‘subsample’: 0.9},
  mean: -34071.12767, std: 18824.45763, params: {‘colsample_bytree’: 0.8, ‘subsample’: 0.6},
  mean: -34306.79986, std: 18037.63492, params: {‘colsample_bytree’: 0.8, ‘subsample’: 0.7},
  mean: -33240.71438, std: 18837.21289, params: {‘colsample_bytree’: 0.8, ‘subsample’: 0.8},
  mean: -34715.48443, std: 20364.52260, params: {‘colsample_bytree’: 0.8, ‘subsample’: 0.9},
  mean: -33987.86273, std: 19097.36063, params: {‘colsample_bytree’: 0.9, ‘subsample’: 0.6},
  mean: -36383.21876, std: 19792.39516, params: {‘colsample_bytree’: 0.9, ‘subsample’: 0.7},
  mean: -33689.36936, std: 18809.76111, params: {‘colsample_bytree’: 0.9, ‘subsample’: 0.8},
  mean: -35748.16003, std: 21143.52892, params: {‘colsample_bytree’: 0.9, ‘subsample’: 0.9}],
 {‘colsample_bytree’: 0.8, ‘subsample’: 0.8},
 -33240.714381367696)&lt;/p&gt;

&lt;h3 id=&quot;5正则化参数调优reg_alphareg_lambda&quot;&gt;5、正则化参数调优（reg_alpha、reg_lambda）&lt;/h3&gt;

&lt;h3 id=&quot;粗调&quot;&gt;粗调&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#Grid seach on subsample and max_features&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#Choose all predictors except target &amp;amp; IDcols&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;param_test6&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'reg_alpha'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gsearch6&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GridSearchCV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;estimator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;XGBRegressor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;booster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'gbtree'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;objective&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'reg:linear'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;eval_metric&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rmse'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;min_child_weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;max_depth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;subsample&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;colsample_bytree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;tree_method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'exact'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;nthread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;scale_pos_weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;27&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_test6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scoring&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'mean_squared_error'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_jobs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gsearch6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;CPU times: user 7.53 s, sys: 202 ms, total: 7.73 s
Wall time: 46.5 s&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;gsearch6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid_scores_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gsearch6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_params_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gsearch6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_score_&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;([mean: -33240.71449, std: 18837.21316, params: {‘reg_alpha’: 1e-05},
mean: -33240.70394, std: 18837.19242, params: {‘reg_alpha’: 0.01},
mean: -33240.61475, std: 18837.01487, params: {‘reg_alpha’: 0.1},
mean: -33655.05163, std: 19188.16195, params: {‘reg_alpha’: 1},
mean: -33518.91580, std: 19324.08680, params: {‘reg_alpha’: 100}],
{‘reg_alpha’: 0.1},
-33240.6147525903)&lt;/p&gt;

&lt;h3 id=&quot;微调&quot;&gt;微调&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#Grid seach on subsample and max_features&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#Choose all predictors except target &amp;amp; IDcols&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;param_test7&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'reg_alpha'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.005&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gsearch7&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GridSearchCV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;estimator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;XGBRegressor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;booster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'gbtree'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;objective&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'reg:linear'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;eval_metric&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rmse'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;min_child_weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;max_depth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;subsample&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;colsample_bytree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;tree_method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'exact'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;nthread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;scale_pos_weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;27&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_test7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scoring&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'mean_squared_error'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_jobs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gsearch7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;CPU times: user 7.49 s, sys: 199 ms, total: 7.69 s
Wall time: 46.2 s&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;gsearch7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid_scores_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gsearch7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_params_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gsearch7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_score_&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;([mean: -33240.71438, std: 18837.21289, params: {‘reg_alpha’: 0},
mean: -33240.71515, std: 18837.21306, params: {‘reg_alpha’: 0.001},
mean: -33240.71029, std: 18837.20469, params: {‘reg_alpha’: 0.005},
mean: -33240.70394, std: 18837.19242, params: {‘reg_alpha’: 0.01},
mean: -33240.66275, std: 18837.11462, params: {‘reg_alpha’: 0.05}],
{‘reg_alpha’: 0.05},
-33240.66275176923)&lt;/p&gt;

&lt;h4 id=&quot;6降低学习率和使用更多的树learning_raten_estimators&quot;&gt;6、降低学习率和使用更多的树（learning_rate、n_estimators）&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#Grid seach on subsample and max_features&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#Choose all predictors except target &amp;amp; IDcols&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;param_test9&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'n_estimators'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'learning_rate'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gsearch9&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GridSearchCV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;estimator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;XGBRegressor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;booster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'gbtree'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;objective&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'reg:linear'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;eval_metric&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rmse'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;min_child_weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;max_depth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;subsample&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;colsample_bytree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;tree_method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'exact'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;nthread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;scale_pos_weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;reg_alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;                           
                    &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;27&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_test9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scoring&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'mean_squared_error'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_jobs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gsearch9&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;CPU times: user 18 s, sys: 400 ms, total: 18.4 s
Wall time: 11min 48s&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;gsearch9&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid_scores_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gsearch9&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_params_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gsearch9&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_score_&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;([mean: -269735.38582, std: 100248.84349, params: {‘learning_rate’: 0.001, ‘n_estimators’: 50},
mean: -248451.90827, std: 91899.96797, params: {‘learning_rate’: 0.001, ‘n_estimators’: 100},
mean: -211548.39700, std: 76958.64307, params: {‘learning_rate’: 0.001, ‘n_estimators’: 200},
mean: -134974.04245, std: 47851.47997, params: {‘learning_rate’: 0.001, ‘n_estimators’: 500},
mean: -73521.66556, std: 25935.98271, params: {‘learning_rate’: 0.001, ‘n_estimators’: 1000},
mean: -134499.16558, std: 47613.16020, params: {‘learning_rate’: 0.01, ‘n_estimators’: 50},
mean: -72947.14830, std: 26031.50160, params: {‘learning_rate’: 0.01, ‘n_estimators’: 100},
mean: -39440.09082, std: 16239.31453, params: {‘learning_rate’: 0.01, ‘n_estimators’: 200},
mean: -33312.98785, std: 18013.88261, params: {‘learning_rate’: 0.01, ‘n_estimators’: 500},
mean: -33663.99313, std: 20179.74172, params: {‘learning_rate’: 0.01, ‘n_estimators’: 1000},
mean: -36502.96591, std: 16225.13167, params: {‘learning_rate’: 0.05, ‘n_estimators’: 50},
mean: -33665.06976, std: 18138.93215, params: {‘learning_rate’: 0.05, ‘n_estimators’: 100},
mean: -34120.16927, std: 20085.98727, params: {‘learning_rate’: 0.05, ‘n_estimators’: 200},
mean: -34177.57983, std: 21188.62796, params: {‘learning_rate’: 0.05, ‘n_estimators’: 500},
mean: -34660.48776, std: 22025.55298, params: {‘learning_rate’: 0.05, ‘n_estimators’: 1000},
mean: -33838.33799, std: 17860.13547, params: {‘learning_rate’: 0.1, ‘n_estimators’: 50},
mean: -33240.66275, std: 18837.11462, params: {‘learning_rate’: 0.1, ‘n_estimators’: 100},
mean: -33181.90461, std: 19910.96435, params: {‘learning_rate’: 0.1, ‘n_estimators’: 200},
mean: -33576.53561, std: 20349.66997, params: {‘learning_rate’: 0.1, ‘n_estimators’: 500},
mean: -34053.72276, std: 20703.38247, params: {‘learning_rate’: 0.1, ‘n_estimators’: 1000},
mean: -35845.98638, std: 21392.95943, params: {‘learning_rate’: 0.2, ‘n_estimators’: 50},
mean: -35973.28358, std: 22094.74565, params: {‘learning_rate’: 0.2, ‘n_estimators’: 100},
mean: -36080.64404, std: 22257.37518, params: {‘learning_rate’: 0.2, ‘n_estimators’: 200},
mean: -36633.99577, std: 22674.09668, params: {‘learning_rate’: 0.2, ‘n_estimators’: 500},
mean: -36964.93338, std: 22742.96590, params: {‘learning_rate’: 0.2, ‘n_estimators’: 1000}],
{‘learning_rate’: 0.1, ‘n_estimators’: 200},
-33181.904612290644)&lt;/p&gt;

&lt;h2 id=&quot;注意&quot;&gt;注意&lt;/h2&gt;

&lt;h3 id=&quot;调完参数之后有两种方式进行使用xgboost&quot;&gt;调完参数之后有两种方式进行使用xgboost&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;1、直接用接口XGBRegressor，fit之后在预测。好处：快，运行的后的效果还可以&lt;/em&gt;     &lt;br /&gt;
&lt;em&gt;2、用xgboost先训练，再预测。好处：鲁棒性比较高&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;首先将之前调完的参数设置好&quot;&gt;首先将之前调完的参数，设置好&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;xgb9&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;XGBRegressor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;booster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'gbtree'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;objective&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'reg:linear'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;eval_metric&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rmse'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;min_child_weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;max_depth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;subsample&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;colsample_bytree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;tree_method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'exact'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;nthread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;scale_pos_weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;reg_alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;                           
                    &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;27&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;第一种方案fit之后在predict预测&quot;&gt;第一种方案fit之后，在predict预测&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;xgb9&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=0.8, eval_metric='rmse', gamma=0.1,
       learning_rate=0.1, max_delta_step=0, max_depth=5,
       min_child_weight=3, missing=None, n_estimators=200, n_jobs=1,
       nthread=4, objective='reg:linear', random_state=0, reg_alpha=0.05,
       reg_lambda=1, scale_pos_weight=1, seed=27, silent=True,
       subsample=0.8, tree_method='exact')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean_squared_error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xgb9&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;163.93821478808687&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;xgb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_importance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xgb9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_num_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2018-02-28-xgboost_parameters.png&quot; alt=&quot;相关系数&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;trainset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xgb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DMatrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;testset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xgb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DMatrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;第二种train完之后在predict&quot;&gt;第二种：train完之后在predict&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xgb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xgb9&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_boost_round&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;watchlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;[0]	train-rmse:494.438
[1]	train-rmse:453.211
[2]	train-rmse:415.193
[3]	train-rmse:381.363
[4]	train-rmse:353.229
…
[9996]	train-rmse:0.43133
[9997]	train-rmse:0.431213
[9998]	train-rmse:0.431125
[9999]	train-rmse:0.431063
CPU times: user 12min 15s, sys: 4.81 s, total: 12min 20s
Wall time: 12min 19s&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;test_predict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;testset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rmse_test_10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean_squared_error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rmse_test_10&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;168.7448358242037&lt;/p&gt;

&lt;p&gt;注意；这里看着第一种方案比第二种方案似乎表现更好一些，但是如果我们拿到线上去测试，会发现第一种方案实际效果差很多。&lt;/p&gt;

&lt;h3 id=&quot;初步原因&quot;&gt;初步原因&lt;/h3&gt;
&lt;p&gt;上图树图是fit 下图树图是train，初步观察到：两个图在前三层节点都是一样的，第四和第五层train节点明显比fit要多，更茂密的树应该是鲁棒性(robust)更好一些，这一点应该是初步可以解释train比fit效果更好的原因
关于Grandient Boosting的原理可以参考这篇文章&lt;a href=&quot;https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/&quot;&gt;Complete Guide to Parameter Tuning in Gradient Boosting (GBM) in Python&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/21167490/36014954-48ec6eea-0da7-11e8-95c8-0b3c0f1d9572.png&quot; alt=&quot;xgb_fit_tree&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/21167490/36014967-5400c830-0da7-11e8-8ac5-21b86d03050f.png&quot; alt=&quot;xgb_train_tree&quot; /&gt;&lt;/p&gt;</content><author><name>Hu Wu</name></author><category term="jekyll" /><summary type="html">本篇初步探索了xgboost在调参数的方法</summary></entry><entry><title type="html">测试jekyll功能</title><link href="http://localhost:4000/2017/12/21/start/" rel="alternate" type="text/html" title="测试jekyll功能" /><published>2017-12-21T00:00:00+08:00</published><updated>2017-12-21T00:00:00+08:00</updated><id>http://localhost:4000/2017/12/21/start</id><content type="html" xml:base="http://localhost:4000/2017/12/21/start/">&lt;h2 id=&quot;本文主要是用来测试&quot;&gt;本文主要是用来测试&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;学习游泳
&lt;img src=&quot;/images/wiki/breaststroke.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
学习一下
测试一下
观察一下
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;code&lt;/code&gt; is defferent&lt;/p&gt;

&lt;p&gt;这是[][#&amp;lt;Jekyll::Document _posts/blog/2014-08-26-takephotos.md collection=posts&amp;gt;, #&amp;lt;Jekyll::Document _posts/2017/2017-12-03-tcp-connect-between-android-emulators.md collection=posts&amp;gt;, #&amp;lt;Jekyll::Document _posts/2017/2017-12-21-start.md collection=posts&amp;gt;, #&amp;lt;Jekyll::Document _posts/2018-02-28-XGboost_param_share.md collection=posts&amp;gt;, #&amp;lt;Jekyll::Document _posts/2018-02-28-xgboost_parameters.md collection=posts&amp;gt;] 清单&lt;/p&gt;</content><author><name>Hu Wu</name></author><category term="jekyll" /><summary type="html">本文主要是用来测试 学习游泳</summary></entry><entry><title type="html">【转】解决两个 Android 模拟器之间无法网络通信的问题</title><link href="http://localhost:4000/2017/12/03/tcp-connect-between-android-emulators/" rel="alternate" type="text/html" title="【转】解决两个 Android 模拟器之间无法网络通信的问题" /><published>2017-12-03T00:00:00+08:00</published><updated>2017-12-03T00:00:00+08:00</updated><id>http://localhost:4000/2017/12/03/tcp-connect-between-android-emulators</id><content type="html" xml:base="http://localhost:4000/2017/12/03/tcp-connect-between-android-emulators/">&lt;p&gt;本文解决的是一个小众场景的问题：&lt;/p&gt;

&lt;p&gt;出差在外，需要调试局域网内的两台 Android 设备之间通过 TCP 通信的情况，可手边又不是随时有多台可用的设备，于是想在笔记本上同时跑两台 Android 模拟器来构造调试环境，但是发现它俩的 IP 地址竟然都是 10.0.2.15，场面一度十分尴尬……&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/android/ip-address.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;谷狗之后，众多相关的博客和问答贴将我引向了官方文档页面：&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://developer.android.com/studio/run/emulator-networking.html#connecting&quot;&gt;Interconnecting emulator instances&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;原来官方指南上解释过相关的知识，现将我关心和以前迷惑的部分翻译摘录如下，如果希望对此有个更全面的了解，还是推荐完整阅读 Android 官方文档里有关 Emulator 的章节 &lt;a href=&quot;https://developer.android.com/studio/run/emulator.html&quot;&gt;https://developer.android.com/studio/run/emulator.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;首先讲一点预备知识，再说解决方案。&lt;/p&gt;

&lt;h2 id=&quot;模拟器的网络地址空间&quot;&gt;模拟器的网络地址空间&lt;/h2&gt;

&lt;p&gt;每个模拟器都运行在一个虚拟路由/防火墙服务后面，这个服务将模拟器和宿主机器的网络接口、配置以及 Internet 隔离开来。对模拟器而言，宿主机器和其它模拟器对它是不可见的，它只知道自己是通过以太网连接到路由/防火墙。&lt;/p&gt;

&lt;p&gt;每个模拟器的虚拟路由管理 10.0.2/24 的网络地址空间，所有地址都是 10.0.2.xx 格式。地址预分配的情况如下：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;网络地址&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;10.0.2.1&lt;/td&gt;
      &lt;td&gt;路由/网络地址&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10.0.2.2&lt;/td&gt;
      &lt;td&gt;宿主机器的 loopback interface，相当于电脑上的 127.0.0.1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10.0.2.3&lt;/td&gt;
      &lt;td&gt;首选 DNS Server&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10.0.2.4 &lt;br /&gt; 10.0.2.5 &lt;br /&gt; 10.0.2.6&lt;/td&gt;
      &lt;td&gt;可选的第二、第三、第四 DNS Server&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10.0.2.15&lt;/td&gt;
      &lt;td&gt;模拟器的网络地址&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;127.0.0.1&lt;/td&gt;
      &lt;td&gt;模拟器的 loopback interface&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;需要注意的是所有模拟器的网络地址分配都是一样的，这样一来，如果有两个模拟器同时运行在一台电脑上，它们都会有各自的路由，并且给两个模拟器分配的 IP 都是 10.0.2.15。它们被路由隔离，相互不可见。&lt;/p&gt;

&lt;p&gt;另外一点就是模拟器上的 127.0.0.1 是指它自己，所以如果想访问宿主机器上运行的服务，要使用 10.0.2.2。&lt;/p&gt;

&lt;h2 id=&quot;实现两台模拟器之间的通信&quot;&gt;实现两台模拟器之间的通信&lt;/h2&gt;

&lt;p&gt;现在来解决标题和文首提到的问题，主要用到了网络重定向。&lt;/p&gt;

&lt;p&gt;假设开发环境是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;PC 是指运行模拟器的宿主电脑&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;emulator-5554 是模拟器 1，将在 TCP 通信中作为 server 端&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;emulator-5556 是模拟器 2，将在 TCP 通信中作为 client 端&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;配置步骤：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;在 emulator-5554 上运行 server，侦听 10.0.2.15:58080&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在 PC 上运行 &lt;code class=&quot;highlighter-rouge&quot;&gt;cat ~/.emulator_console_auth_token&lt;/code&gt;，得到一个 token&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在 PC 上运行&lt;/p&gt;

    &lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; telnet localhost 5554
 auth &amp;lt;token&amp;gt;
 redir add tcp:51212:58080
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;token&amp;gt;&lt;/code&gt; 是指第 2 步中得到的 token。&lt;/p&gt;

    &lt;p&gt;51212 是 PC 端口，58080 是 5554 模拟器的端口。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在 emulator-5556 上运行 client 程序，连接 10.0.2.2:51212&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;至此，两台模拟器之间已经可以通过 TCP 愉快地通信了。&lt;/p&gt;

&lt;p&gt;它们之间的网络连接和通信示意图如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/android/emulators-communication.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;以上步骤中用到的端口号都是可以根据你的需求替换的&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Windows 下 telnet 命令默认没有启用，具体启用方法请搜狗一下&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;模拟器的网络限制&quot;&gt;模拟器的网络限制&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;模拟器上运行的 Apps 可以连接到宿主电脑上的网络，但这是通过模拟器间接实现，不是直接连到宿主电脑的网卡。模拟器可以看作是宿主电脑上运行的一个普通程序。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;因为模拟器的特殊网络配置，可能无法支持一些网络协议，比如 ping 命令使用的 ICMP 协议。目前，模拟器不支持 IGMP 和 multicast。&lt;/p&gt;

    &lt;p&gt;&lt;em&gt;试验了一下，模拟器的 shell 里 &lt;code class=&quot;highlighter-rouge&quot;&gt;ping www.sogou.com&lt;/code&gt; 一直卡在那，在手机的 shell 里就可以。&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;额外的发现&quot;&gt;额外的发现&lt;/h2&gt;

&lt;p&gt;在阅读 Android 官方文档里关于模拟器的章节时，意外地发现有一节 &lt;a href=&quot;https://developer.android.com/studio/run/emulator-networking.html#calling&quot;&gt;Sending a voice call or SMS to another emulator instance&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;就是说模拟器可以给另外的模拟器打电话和发短信，电话号码就是端口号，比如 emulator-5554 模拟器，电话号码就是 5554，这个号码也可以从模拟器的窗口标题栏上找到，比如 &lt;code class=&quot;highlighter-rouge&quot;&gt;Android Emulator - Nexus_5X_API_19:5554&lt;/code&gt;，里面那个 5554 就是。&lt;/p&gt;

&lt;h2 id=&quot;后话&quot;&gt;后话&lt;/h2&gt;

&lt;p&gt;天下博文，大部分都逃不出官方文档与公开源码的范畴（比如本文就是），而且都是选定文档里讲的某一小部分来进行讲解演绎，这在作为扩展视野、快速上手、快速解决问题等用途时还是比较实用的，但如果想系统、全面地学习，官方文档一般是更好的选择。&lt;/p&gt;</content><author><name>Hu Wu</name></author><summary type="html">本文解决的是一个小众场景的问题：</summary></entry><entry><title type="html">【转】摄影教训总结</title><link href="http://localhost:4000/2014/08/26/takephotos/" rel="alternate" type="text/html" title="【转】摄影教训总结" /><published>2014-08-26T00:00:00+08:00</published><updated>2014-08-26T00:00:00+08:00</updated><id>http://localhost:4000/2014/08/26/takephotos</id><content type="html" xml:base="http://localhost:4000/2014/08/26/takephotos/">&lt;h3 id=&quot;2014-年-8-月-杭州&quot;&gt;2014 年 8 月 杭州&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;以人为主体没错，但是要有远有近，拍出来全是脸和上半身也不好。&lt;/li&gt;
  &lt;li&gt;偶尔兼顾景色，不是所有情况下虚化背景都是加分。&lt;/li&gt;
  &lt;li&gt;一般情况下色彩鲜艳的衣服拍出来会更好看。&lt;/li&gt;
  &lt;li&gt;人像镜头不是万能的，大光圈容易虚焦，取景范围影响构图，这些都需要更好地考虑。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;2014-年-6-月-武汉&quot;&gt;2014 年 6 月 武汉&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;照顾好拍摄对象的心情，她开心和配合了，才容易出好片。&lt;/li&gt;
  &lt;li&gt;如果她真的不愿意拍，就不拍了吧，否则出来基本也是废的。&lt;/li&gt;
  &lt;li&gt;蓝天白云绿水真的很容易出好片，但是阴天加浑浊的长江边还是不要轻易挑战了。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;2014-年-3-月-武汉&quot;&gt;2014 年 3 月 武汉&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;气氛要活泼一点，不然模特摆拍容易表情僵硬。&lt;/li&gt;
  &lt;li&gt;光圈优先在室外光线好的情况下容易过曝。&lt;/li&gt;
  &lt;li&gt;只挑拍得最好的片发给模特看，如果没有出好片，宁愿不发。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/images/qrcode.jpg&quot; alt=&quot;pictest&quot; /&gt;&lt;/p&gt;</content><author><name>Hu Wu</name></author><summary type="html">2014 年 8 月 杭州</summary></entry></feed>