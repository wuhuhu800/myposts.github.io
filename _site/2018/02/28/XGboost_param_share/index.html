<!DOCTYPE html>
<html lang="zh-cmn-Hans" prefix="og: http://ogp.me/ns#" class="han-init">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <title>XGBoost 参数调优(python) &mdash; 问道</title>
    <link rel="stylesheet" href="http://localhost:4000/assets/vendor/primer-css/css/primer.css">
    <link rel="stylesheet" href="http://localhost:4000/assets/vendor/primer-markdown/dist/user-content.min.css">
    <link rel="stylesheet" href="http://localhost:4000/assets/vendor/octicons/octicons/octicons.css">
    <link rel="stylesheet" href="http://localhost:4000/assets/css/components/collection.css">
    <link rel="stylesheet" href="http://localhost:4000/assets/css/components/repo-card.css">
    <link rel="stylesheet" href="http://localhost:4000/assets/css/sections/repo-list.css">
    <link rel="stylesheet" href="http://localhost:4000/assets/css/sections/mini-repo-list.css">
    <link rel="stylesheet" href="http://localhost:4000/assets/css/components/boxed-group.css">
    <link rel="stylesheet" href="http://localhost:4000/assets/css/globals/common.css">
    <link rel="stylesheet" href="http://localhost:4000/assets/vendor/share.js/dist/css/share.min.css">
    <link rel="stylesheet" href="http://localhost:4000/assets/css/globals/responsive.css">
    <link rel="stylesheet" href="http://localhost:4000/assets/css/posts/index.css">
    <!-- Latest compiled and minified CSS -->
    

    
    <link rel="canonical" href="http://localhost:4000/2018/02/28/XGboost_param_share/">
    <link rel="alternate" type="application/atom+xml" title="问道" href="http://localhost:4000/feed.xml">
    <link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
    
    <meta property="og:title" content="XGBoost 参数调优(python)">
      
    <meta name="keywords" content="机器学习,Xgboost,调参,python">
    <meta name="og:keywords" content="机器学习,Xgboost,调参,python">
      
    <meta name="description" content="本篇初步探索了xgboost在调参数的方法">
    <meta name="og:description" content="本篇初步探索了xgboost在调参数的方法">
      
    
    
        
    
    <meta property="og:url" content="http://localhost:4000/2018/02/28/XGboost_param_share/">
    <meta property="og:site_name" content="问道">
    <meta property="og:type" content="article">
    <meta property="og:locale" content="zh_CN" />
    
    <meta property="article:published_time" content="2018-02-28">
    
    <script src="http://localhost:4000/assets/vendor/jquery/dist/jquery.min.js"></script>
    <script src="http://localhost:4000/assets/js/jquery-ui.js"></script>
    <script type="text/javascript">
    function toggleMenu() {
        var nav = document.getElementsByClassName("site-header-nav")[0];
        if (nav.style.display == "inline-flex") {
          nav.style.display = "none";
        } else {
          nav.style.display = "inline-flex";
        }
    }
    </script>
</head>
<body class="" data-mz="">
    <header class="site-header">
        <div class="container">
            <h1><a href="http://localhost:4000/" title="问道"><span class="octicon octicon-mark-github"></span> 问道</a></h1>
            <button class="collapsed mobile-visible" type="button" onclick="toggleMenu();">
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <nav class="site-header-nav" role="navigation">
                
                <a href="http://localhost:4000/" class=" site-header-nav-item" target="" title="首页">首页</a>
                
                <a href="http://localhost:4000/categories/" class=" site-header-nav-item" target="" title="分类">分类</a>
                
                <a href="http://localhost:4000/wiki/" class=" site-header-nav-item" target="" title="维基">维基</a>
                
                <a href="http://localhost:4000/links/" class=" site-header-nav-item" target="" title="链接">链接</a>
                
                <a href="http://localhost:4000/about/" class=" site-header-nav-item" target="" title="关于">关于</a>
                
            </nav>
        </div>
    </header>
    <!-- / header -->

    <section class="collection-head small geopattern" data-pattern-id="XGBoost 参数调优(py">
<div class="container">
  <div class="columns">
    <div class="column three-fourths">
      <div class="collection-title">
        <h1 class="collection-header">XGBoost 参数调优(python)</h1>
        <div class="collection-info">
          
          <span class="meta-info">
            <span class="octicon octicon-calendar"></span> 2018/02/28
          </span>
          
          
          <span class="meta-info">
            <span class="octicon octicon-file-directory"></span>
            <a href="http://localhost:4000/categories/#机器学习" title="机器学习">机器学习</a>
          </span>
          
        </div>
      </div>
    </div>
  </div>
</div>
</section>
<!-- / .banner -->
<section class="container content">
<div class="columns">
  <div class="column three-fourths" >
    <article class="article-content markdown-body">
    <p>本篇初步探索了xgboost在调参数的方法</p>

<p><strong>背景</strong>：数据科学里，首先要对数据特征的提取建模，然后用机器学习模拟预测。目前来说，工业界暂时不清楚，但是在只要涉及数据科学的比赛，机器学习模型肯定少补了Xgboost。Xgboost的参数非常繁多（50多个参数），本次主要介绍如何进行Xgboost调参</p>

<h2 id="调参原理">调参原理：</h2>
<p><em>1、利用sklearn的网格搜索GridSearchCV进行调试，但是GridSearchCV无法直接对xgboost进行调试</em>
<em>2、利用xgboost的sklearn接口<a href="http://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn">XGBRegressor/XGBClassifier</a>,利用接口，将xgboost的参数带入到GridSearchCV进行遍历调优</em></p>

<h2 id="调参原则">调参原则：</h2>
<p><em>1、参数先粗调再微调</em>
<em>2、参数先调对结果影响大的（哪些影响大，可以上网先找找）</em>
<em>3、分批次调参</em></p>

<h2 id="xgboost的参数">Xgboost的参数</h2>

<ul>
  <li>General parameters relates to which booster we are using to do boosting, commonly tree or linear model</li>
  <li>Booster parameters depends on which booster you have chosen</li>
  <li>Learning Task parameters that decides on the learning scenario, for example, regression tasks may use different parameters with ranking tasks.</li>
  <li>Command line parameters that relates to behavior of CLI version of xgboost.</li>
</ul>

<h3 id="调参的顺序">调参的顺序：</h3>
<p><em>1、选定一组基准参数，这些参数有经验的话，用经验值，没有经验可以用官方的默认值</em>
<em>2 、max_depth 和 min_child_weight 参数调优</em>
<em>3、gamma参数调优</em>
<em>4、调整subsample 和 colsample_bytree 参数调优</em>
<em>5、正则化参数调优（reg_alpha、reg_lambda</em>
<em>6、降低学习率和使用更多的树（learning_rate、n_estimators）</em>
<em>7、可以探索的参数max_delta_step 、scale_pos_weight、base_score</em></p>

<p>接下来让我们先导入对应的模块，且对数据进行一定的处理</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#Import libraries:</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="n">xgb</span>
<span class="kn">from</span> <span class="nn">xgboost.sklearn</span> <span class="kn">import</span> <span class="n">XGBRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">cross_validation</span><span class="p">,</span> <span class="n">metrics</span>   <span class="c">#Additional     scklearn functions</span>
<span class="kn">from</span> <span class="nn">sklearn.grid_search</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>   <span class="c">#Perforing grid search</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="n">plt</span>
<span class="c">#import warnings</span>
<span class="c">#warnings.filterwarnings('ignore')</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">from</span> <span class="nn">matplotlib.pylab</span> <span class="kn">import</span> <span class="n">rcParams</span>
<span class="n">rcParams</span><span class="p">[</span><span class="s">'figure.figsize'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">4</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">fbeta_score</span><span class="p">,</span> <span class="n">make_scorer</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'../../raw/LiChuan/trainSaleDate.csv'</span><span class="p">)</span>
<span class="c"># 去掉 2012 年数据, 噪音太多</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'year'</span><span class="p">]</span><span class="o">==</span><span class="mi">2012</span><span class="p">)</span>

<span class="n">train</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">sale_quantity</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'class_id'</span><span class="p">,</span><span class="s">'sale_quantity'</span><span class="p">,</span> <span class="s">'sale_date'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c"># train_test = pd.concat([train, test]).reset_index(drop=True)</span>
<span class="n">year_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'year'</span><span class="p">],</span> <span class="n">prefix</span><span class="o">=</span><span class="s">'year'</span><span class="p">)</span>
<span class="n">month_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'month'</span><span class="p">],</span> <span class="n">prefix</span><span class="o">=</span><span class="s">'month'</span><span class="p">)</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">train</span><span class="p">,</span> <span class="n">year_dummies</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">train</span><span class="p">,</span> <span class="n">month_dummies</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'year'</span><span class="p">,</span> <span class="s">'month'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">train</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c"># 获取 2017-10 数据作为测试集</span>
<span class="n">test_X</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="o">-</span><span class="mi">140</span><span class="p">:]</span>
<span class="n">test_Y</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="o">-</span><span class="mi">140</span><span class="p">:]</span>

<span class="c"># 2012-01 至 2017-10 作为训练集</span>
<span class="n">train_X</span> <span class="o">=</span> <span class="n">train</span><span class="p">[:</span><span class="o">-</span><span class="mi">140</span><span class="p">]</span>
<span class="n">train_Y</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[:</span><span class="o">-</span><span class="mi">140</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">modelfit</span><span class="p">(</span><span class="n">alg</span><span class="p">,</span><span class="n">useTrainCV</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">cv_folds</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>

    <span class="k">if</span> <span class="n">useTrainCV</span><span class="p">:</span>
        <span class="n">xgb_param</span> <span class="o">=</span> <span class="n">alg</span><span class="o">.</span><span class="n">get_xgb_params</span><span class="p">()</span>
        <span class="n">xgtrain</span> <span class="o">=</span><span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="n">train_Y</span><span class="p">)</span>
        <span class="n">xgtest</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
        <span class="n">cvresult</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">cv</span><span class="p">(</span><span class="n">xgb_param</span><span class="p">,</span> <span class="n">xgtrain</span><span class="p">,</span> <span class="n">num_boost_round</span><span class="o">=</span><span class="n">alg</span><span class="o">.</span><span class="n">get_params</span><span class="p">()[</span><span class="s">'n_estimators'</span><span class="p">],</span> <span class="n">nfold</span><span class="o">=</span><span class="n">cv_folds</span><span class="p">,</span>
                          <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="n">early_stopping_rounds</span><span class="p">,</span><span class="n">show_stdv</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">alg</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">cvresult</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="c">#cvresult.shape[0]和alg.get_params()['n_estimators']值一样</span>

    <span class="c">#Fit the algorithm on the data</span>
    <span class="n">alg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span><span class="n">eval_metric</span><span class="o">=</span><span class="s">'rmse'</span><span class="p">)</span>
    <span class="c">#Predict training set:</span>
    <span class="n">dtrain_predictions</span> <span class="o">=</span> <span class="n">alg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span>
    <span class="c">#Print model report:</span>
    <span class="k">print</span><span class="p">(</span><span class="s">" Score (Train): </span><span class="si">%</span><span class="s">f"</span> <span class="o">%</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">train_Y</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtrain_predictions</span><span class="p">))</span>
    <span class="c">#Predict on testing data:</span>
    <span class="n">dtest_predictions</span> <span class="o">=</span> <span class="n">alg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Score (Test): </span><span class="si">%</span><span class="s">f"</span> <span class="o">%</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">test_Y</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtest_predictions</span><span class="p">))</span>

</code></pre></div></div>

<h4 id="1选定一组基准参数这些参数有经验的话用经验值没有经验可以用官方的默认值">1、选定一组基准参数，这些参数有经验的话，用经验值，没有经验可以用官方的默认值</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">xgb1</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">booster</span><span class="o">=</span><span class="s">'gbtree'</span><span class="p">,</span>
                    <span class="n">objective</span><span class="o">=</span> <span class="s">'reg:linear'</span><span class="p">,</span>
                    <span class="n">eval_metric</span><span class="o">=</span><span class="s">'rmse'</span><span class="p">,</span>
                    <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">min_child_weight</span><span class="o">=</span> <span class="mf">1.1</span><span class="p">,</span>
                    <span class="n">max_depth</span><span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                    <span class="n">subsample</span><span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
                    <span class="n">colsample_bytree</span><span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
                    <span class="n">tree_method</span><span class="o">=</span> <span class="s">'exact'</span><span class="p">,</span>
                    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                    <span class="n">nthread</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                    <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">seed</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
<span class="n">modelfit</span><span class="p">(</span><span class="n">xgb1</span><span class="p">)</span>
</code></pre></div></div>

<p>Score (Train): 8054.387826</p>

<p>Score (Test): 27418.413465</p>

<h4 id="xgb1的参数">xgb1的参数</h4>
<p>base_score=0.5, booster=’gbtree’, colsample_bylevel=1,
colsample_bytree=0.8, eval_metric=’rmse’, gamma=0.1,
learning_rate=0.1, max_delta_step=0, max_depth=5,
min_child_weight=1.1, missing=None, n_estimators=400, n_jobs=1,
nthread=4, objective=’reg:linear’, random_state=0, reg_alpha=0,
reg_lambda=1, scale_pos_weight=1, seed=27, silent=True,
subsample=0.8, tree_method=’exact’</p>

<h4 id="2-max_depth-和-min_child_weight-参数调优">2、 max_depth 和 min_child_weight 参数调优</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>

<span class="c">#Grid seach on subsample and max_features</span>
<span class="c">#Choose all predictors except target &amp; IDcols</span>
<span class="n">param_test1</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'max_depth'</span><span class="p">:[</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">9</span><span class="p">],</span>
    <span class="s">'min_child_weight'</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">]</span>
<span class="p">}</span>
<span class="n">gsearch1</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">booster</span><span class="o">=</span><span class="s">'gbtree'</span><span class="p">,</span>
                    <span class="n">objective</span><span class="o">=</span> <span class="s">'reg:linear'</span><span class="p">,</span>
                    <span class="n">eval_metric</span><span class="o">=</span><span class="s">'rmse'</span><span class="p">,</span>
                    <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">min_child_weight</span><span class="o">=</span> <span class="mf">1.1</span><span class="p">,</span>
                    <span class="n">max_depth</span><span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                    <span class="n">subsample</span><span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
                    <span class="n">colsample_bytree</span><span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
                    <span class="n">tree_method</span><span class="o">=</span> <span class="s">'exact'</span><span class="p">,</span>
                    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                    <span class="n">nthread</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                    <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">seed</span><span class="o">=</span><span class="mi">27</span><span class="p">),</span>
                       <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_test1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">iid</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">gsearch1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span><span class="n">train_Y</span><span class="p">)</span>
</code></pre></div></div>
<p>CPU times: user 8.41 s, sys: 323 ms, total: 8.73 s
Wall time: 1min 50s</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gsearch1</span><span class="o">.</span><span class="n">grid_scores_</span><span class="p">,</span> <span class="n">gsearch1</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="n">gsearch1</span><span class="o">.</span><span class="n">best_score_</span>
</code></pre></div></div>
<p>([mean: -37307.30173, std: 20190.10346, params: {‘max_depth’: 3, ‘min_child_weight’: 1},
  mean: -37858.56838, std: 20117.31618, params: {‘max_depth’: 3, ‘min_child_weight’: 3},
  mean: -37074.47698, std: 18889.70050, params: {‘max_depth’: 3, ‘min_child_weight’: 5},
  mean: -33870.23259, std: 19987.57504, params: {‘max_depth’: 5, ‘min_child_weight’: 1},
  mean: -33240.71438, std: 18837.21289, params: {‘max_depth’: 5, ‘min_child_weight’: 3},
  mean: -36997.23968, std: 22463.08107, params: {‘max_depth’: 5, ‘min_child_weight’: 5},
  mean: -33965.78497, std: 18547.66643, params: {‘max_depth’: 7, ‘min_child_weight’: 1},
  mean: -34735.79444, std: 20149.70986, params: {‘max_depth’: 7, ‘min_child_weight’: 3},
  mean: -37111.82576, std: 22824.75284, params: {‘max_depth’: 7, ‘min_child_weight’: 5},
  mean: -35508.45759, std: 19274.54528, params: {‘max_depth’: 9, ‘min_child_weight’: 1},
  mean: -35914.95148, std: 20508.98895, params: {‘max_depth’: 9, ‘min_child_weight’: 3},
  mean: -36943.84821, std: 20971.33128, params: {‘max_depth’: 9, ‘min_child_weight’: 5}],
 {‘max_depth’: 5, ‘min_child_weight’: 3},
 -33240.714381367696)</p>

<h4 id="不放心的话尝试一下其他值">不放心的话尝试一下其他值</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>
<span class="c">#Grid seach on subsample and max_features</span>
<span class="c">#Choose all predictors except target &amp; IDcols</span>
<span class="n">param_test1b</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'min_child_weight'</span><span class="p">:[</span><span class="mi">6</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">12</span><span class="p">]</span>
<span class="p">}</span>
<span class="n">gsearch1b</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">booster</span><span class="o">=</span><span class="s">'gbtree'</span><span class="p">,</span>
                    <span class="n">objective</span><span class="o">=</span> <span class="s">'reg:linear'</span><span class="p">,</span>
                    <span class="n">eval_metric</span><span class="o">=</span><span class="s">'rmse'</span><span class="p">,</span>
                    <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">min_child_weight</span><span class="o">=</span> <span class="mf">1.1</span><span class="p">,</span>
                    <span class="n">max_depth</span><span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                    <span class="n">subsample</span><span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
                    <span class="n">colsample_bytree</span><span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
                    <span class="n">tree_method</span><span class="o">=</span> <span class="s">'exact'</span><span class="p">,</span>
                    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                    <span class="n">nthread</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                    <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">seed</span><span class="o">=</span><span class="mi">27</span><span class="p">),</span>
                       <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_test1b</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">iid</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">gsearch1b</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span><span class="n">train_Y</span><span class="p">)</span>
</code></pre></div></div>
<p>CPU times: user 7.28 s, sys: 187 ms, total: 7.46 s
Wall time: 36.1 s</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gsearch1b</span><span class="o">.</span><span class="n">grid_scores_</span><span class="p">,</span> <span class="n">gsearch1b</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="n">gsearch1b</span><span class="o">.</span><span class="n">best_score_</span>
</code></pre></div></div>
<p>([mean: -37171.16050, std: 21067.04892, params: {‘min_child_weight’: 6},
mean: -36495.04327, std: 20191.87333, params: {‘min_child_weight’: 8},
mean: -36298.35708, std: 19605.68520, params: {‘min_child_weight’: 10},
mean: -35836.89718, std: 18897.25594, params: {‘min_child_weight’: 12}],
{‘min_child_weight’: 12},
-35836.89718422033)</p>

<h4 id="3gamma参数调优">3、gamma参数调优</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>
<span class="n">param_test3</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'gamma'</span><span class="p">:[</span><span class="n">i</span><span class="o">/</span><span class="mf">10.0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">)]</span>
<span class="p">}</span>
<span class="n">gsearch3</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">booster</span><span class="o">=</span><span class="s">'gbtree'</span><span class="p">,</span>
                    <span class="n">objective</span><span class="o">=</span> <span class="s">'reg:linear'</span><span class="p">,</span>
                    <span class="n">eval_metric</span><span class="o">=</span><span class="s">'rmse'</span><span class="p">,</span>
                    <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">min_child_weight</span><span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
                    <span class="n">max_depth</span><span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                    <span class="n">subsample</span><span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
                    <span class="n">colsample_bytree</span><span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
                    <span class="n">tree_method</span><span class="o">=</span> <span class="s">'exact'</span><span class="p">,</span>
                    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                    <span class="n">nthread</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                    <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">seed</span><span class="o">=</span><span class="mi">27</span><span class="p">),</span>
                       <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_test3</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">iid</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">gsearch3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span><span class="n">train_Y</span><span class="p">)</span>
</code></pre></div></div>

<p>CPU times: user 7.82 s, sys: 227 ms, total: 8.05 s
Wall time: 48.6 s</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gsearch3</span><span class="o">.</span><span class="n">grid_scores_</span><span class="p">,</span> <span class="n">gsearch3</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="n">gsearch3</span><span class="o">.</span><span class="n">best_score_</span>
</code></pre></div></div>

<p>([mean: -33240.71438, std: 18837.21289, params: {‘gamma’: 0.0},
  mean: -33240.71438, std: 18837.21289, params: {‘gamma’: 0.1},
  mean: -33240.71438, std: 18837.21289, params: {‘gamma’: 0.2},
  mean: -33240.71438, std: 18837.21289, params: {‘gamma’: 0.3},
  mean: -33240.71438, std: 18837.21289, params: {‘gamma’: 0.4}],
 {‘gamma’: 0.0},
 -33240.714381367696)</p>

<h4 id="4调整subsample-和-colsample_bytree-参数调优">4、调整subsample 和 colsample_bytree 参数调优</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>
<span class="c">#Grid seach on subsample and max_features</span>
<span class="c">#Choose all predictors except target &amp; IDcols</span>
<span class="n">param_test4</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'subsample'</span><span class="p">:[</span><span class="n">i</span><span class="o">/</span><span class="mf">10.0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">10</span><span class="p">)],</span>
    <span class="s">'colsample_bytree'</span><span class="p">:[</span><span class="n">i</span><span class="o">/</span><span class="mf">10.0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">10</span><span class="p">)]</span>
<span class="p">}</span>
<span class="n">gsearch4</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">booster</span><span class="o">=</span><span class="s">'gbtree'</span><span class="p">,</span>
                    <span class="n">objective</span><span class="o">=</span> <span class="s">'reg:linear'</span><span class="p">,</span>
                    <span class="n">eval_metric</span><span class="o">=</span><span class="s">'rmse'</span><span class="p">,</span>
                    <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">min_child_weight</span><span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
                    <span class="n">max_depth</span><span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                    <span class="n">subsample</span><span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
                    <span class="n">colsample_bytree</span><span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
                    <span class="n">tree_method</span><span class="o">=</span> <span class="s">'exact'</span><span class="p">,</span>
                    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                    <span class="n">nthread</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                    <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">seed</span><span class="o">=</span><span class="mi">27</span><span class="p">),</span>
                       <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_test4</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">iid</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">gsearch4</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span><span class="n">train_Y</span><span class="p">)</span>
</code></pre></div></div>
<p>CPU times: user 9.08 s, sys: 409 ms, total: 9.49 s
Wall time: 1min 56s</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gsearch4</span><span class="o">.</span><span class="n">grid_scores_</span><span class="p">,</span> <span class="n">gsearch4</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="n">gsearch4</span><span class="o">.</span><span class="n">best_score_</span>
</code></pre></div></div>

<p>([mean: -33599.72943, std: 18191.85111, params: {‘colsample_bytree’: 0.6, ‘subsample’: 0.6},
  mean: -34504.14133, std: 18332.87810, params: {‘colsample_bytree’: 0.6, ‘subsample’: 0.7},
  mean: -34742.90855, std: 20106.86473, params: {‘colsample_bytree’: 0.6, ‘subsample’: 0.8},
  mean: -34180.71176, std: 21119.88727, params: {‘colsample_bytree’: 0.6, ‘subsample’: 0.9},
  mean: -33706.05489, std: 17873.54056, params: {‘colsample_bytree’: 0.7, ‘subsample’: 0.6},
  mean: -35365.73247, std: 20734.72408, params: {‘colsample_bytree’: 0.7, ‘subsample’: 0.7},
  mean: -36003.56230, std: 20460.12605, params: {‘colsample_bytree’: 0.7, ‘subsample’: 0.8},
  mean: -35102.41564, std: 20596.99663, params: {‘colsample_bytree’: 0.7, ‘subsample’: 0.9},
  mean: -34071.12767, std: 18824.45763, params: {‘colsample_bytree’: 0.8, ‘subsample’: 0.6},
  mean: -34306.79986, std: 18037.63492, params: {‘colsample_bytree’: 0.8, ‘subsample’: 0.7},
  mean: -33240.71438, std: 18837.21289, params: {‘colsample_bytree’: 0.8, ‘subsample’: 0.8},
  mean: -34715.48443, std: 20364.52260, params: {‘colsample_bytree’: 0.8, ‘subsample’: 0.9},
  mean: -33987.86273, std: 19097.36063, params: {‘colsample_bytree’: 0.9, ‘subsample’: 0.6},
  mean: -36383.21876, std: 19792.39516, params: {‘colsample_bytree’: 0.9, ‘subsample’: 0.7},
  mean: -33689.36936, std: 18809.76111, params: {‘colsample_bytree’: 0.9, ‘subsample’: 0.8},
  mean: -35748.16003, std: 21143.52892, params: {‘colsample_bytree’: 0.9, ‘subsample’: 0.9}],
 {‘colsample_bytree’: 0.8, ‘subsample’: 0.8},
 -33240.714381367696)</p>

<h3 id="5正则化参数调优reg_alphareg_lambda">5、正则化参数调优（reg_alpha、reg_lambda）</h3>

<h3 id="粗调">粗调</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>
<span class="c">#Grid seach on subsample and max_features</span>
<span class="c">#Choose all predictors except target &amp; IDcols</span>
<span class="n">param_test6</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'reg_alpha'</span><span class="p">:[</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="p">}</span>
<span class="n">gsearch6</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">booster</span><span class="o">=</span><span class="s">'gbtree'</span><span class="p">,</span>
                    <span class="n">objective</span><span class="o">=</span> <span class="s">'reg:linear'</span><span class="p">,</span>
                    <span class="n">eval_metric</span><span class="o">=</span><span class="s">'rmse'</span><span class="p">,</span>
                    <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">min_child_weight</span><span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
                    <span class="n">max_depth</span><span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                    <span class="n">subsample</span><span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
                    <span class="n">colsample_bytree</span><span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
                    <span class="n">tree_method</span><span class="o">=</span> <span class="s">'exact'</span><span class="p">,</span>
                    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                    <span class="n">nthread</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                    <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">seed</span><span class="o">=</span><span class="mi">27</span><span class="p">),</span>
                       <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_test6</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">iid</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">gsearch6</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span><span class="n">train_Y</span><span class="p">)</span>

</code></pre></div></div>
<p>CPU times: user 7.53 s, sys: 202 ms, total: 7.73 s
Wall time: 46.5 s</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gsearch6</span><span class="o">.</span><span class="n">grid_scores_</span><span class="p">,</span> <span class="n">gsearch6</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="n">gsearch6</span><span class="o">.</span><span class="n">best_score_</span>
</code></pre></div></div>

<p>([mean: -33240.71449, std: 18837.21316, params: {‘reg_alpha’: 1e-05},
mean: -33240.70394, std: 18837.19242, params: {‘reg_alpha’: 0.01},
mean: -33240.61475, std: 18837.01487, params: {‘reg_alpha’: 0.1},
mean: -33655.05163, std: 19188.16195, params: {‘reg_alpha’: 1},
mean: -33518.91580, std: 19324.08680, params: {‘reg_alpha’: 100}],
{‘reg_alpha’: 0.1},
-33240.6147525903)</p>

<h3 id="微调">微调</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>
<span class="c">#Grid seach on subsample and max_features</span>
<span class="c">#Choose all predictors except target &amp; IDcols</span>
<span class="n">param_test7</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'reg_alpha'</span><span class="p">:[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.005</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">]</span>
<span class="p">}</span>
<span class="n">gsearch7</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">booster</span><span class="o">=</span><span class="s">'gbtree'</span><span class="p">,</span>
                    <span class="n">objective</span><span class="o">=</span> <span class="s">'reg:linear'</span><span class="p">,</span>
                    <span class="n">eval_metric</span><span class="o">=</span><span class="s">'rmse'</span><span class="p">,</span>
                    <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">min_child_weight</span><span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
                    <span class="n">max_depth</span><span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                    <span class="n">subsample</span><span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
                    <span class="n">colsample_bytree</span><span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
                    <span class="n">tree_method</span><span class="o">=</span> <span class="s">'exact'</span><span class="p">,</span>
                    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                    <span class="n">nthread</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                    <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">seed</span><span class="o">=</span><span class="mi">27</span><span class="p">),</span>
                       <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_test7</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">iid</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">gsearch7</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span><span class="n">train_Y</span><span class="p">)</span>


</code></pre></div></div>
<p>CPU times: user 7.49 s, sys: 199 ms, total: 7.69 s
Wall time: 46.2 s</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gsearch7</span><span class="o">.</span><span class="n">grid_scores_</span><span class="p">,</span> <span class="n">gsearch7</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="n">gsearch7</span><span class="o">.</span><span class="n">best_score_</span>
</code></pre></div></div>
<p>([mean: -33240.71438, std: 18837.21289, params: {‘reg_alpha’: 0},
mean: -33240.71515, std: 18837.21306, params: {‘reg_alpha’: 0.001},
mean: -33240.71029, std: 18837.20469, params: {‘reg_alpha’: 0.005},
mean: -33240.70394, std: 18837.19242, params: {‘reg_alpha’: 0.01},
mean: -33240.66275, std: 18837.11462, params: {‘reg_alpha’: 0.05}],
{‘reg_alpha’: 0.05},
-33240.66275176923)</p>

<h4 id="6降低学习率和使用更多的树learning_raten_estimators">6、降低学习率和使用更多的树（learning_rate、n_estimators）</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>
<span class="c">#Grid seach on subsample and max_features</span>
<span class="c">#Choose all predictors except target &amp; IDcols</span>
<span class="n">param_test9</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'n_estimators'</span><span class="p">:[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span><span class="mi">1000</span><span class="p">],</span>
    <span class="s">'learning_rate'</span><span class="p">:[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span><span class="mf">0.2</span><span class="p">]</span>
<span class="p">}</span>
<span class="n">gsearch9</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">booster</span><span class="o">=</span><span class="s">'gbtree'</span><span class="p">,</span>
                    <span class="n">objective</span><span class="o">=</span> <span class="s">'reg:linear'</span><span class="p">,</span>
                    <span class="n">eval_metric</span><span class="o">=</span><span class="s">'rmse'</span><span class="p">,</span>
                    <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">min_child_weight</span><span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
                    <span class="n">max_depth</span><span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                    <span class="n">subsample</span><span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
                    <span class="n">colsample_bytree</span><span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
                    <span class="n">tree_method</span><span class="o">=</span> <span class="s">'exact'</span><span class="p">,</span>
                    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                    <span class="n">nthread</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                    <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">reg_alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>                           
                    <span class="n">seed</span><span class="o">=</span><span class="mi">27</span><span class="p">),</span>
                       <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_test9</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">iid</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">gsearch9</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span><span class="n">train_Y</span><span class="p">)</span>


</code></pre></div></div>
<p>CPU times: user 18 s, sys: 400 ms, total: 18.4 s
Wall time: 11min 48s</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gsearch9</span><span class="o">.</span><span class="n">grid_scores_</span><span class="p">,</span> <span class="n">gsearch9</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="n">gsearch9</span><span class="o">.</span><span class="n">best_score_</span>
</code></pre></div></div>

<p>([mean: -269735.38582, std: 100248.84349, params: {‘learning_rate’: 0.001, ‘n_estimators’: 50},
mean: -248451.90827, std: 91899.96797, params: {‘learning_rate’: 0.001, ‘n_estimators’: 100},
mean: -211548.39700, std: 76958.64307, params: {‘learning_rate’: 0.001, ‘n_estimators’: 200},
mean: -134974.04245, std: 47851.47997, params: {‘learning_rate’: 0.001, ‘n_estimators’: 500},
mean: -73521.66556, std: 25935.98271, params: {‘learning_rate’: 0.001, ‘n_estimators’: 1000},
mean: -134499.16558, std: 47613.16020, params: {‘learning_rate’: 0.01, ‘n_estimators’: 50},
mean: -72947.14830, std: 26031.50160, params: {‘learning_rate’: 0.01, ‘n_estimators’: 100},
mean: -39440.09082, std: 16239.31453, params: {‘learning_rate’: 0.01, ‘n_estimators’: 200},
mean: -33312.98785, std: 18013.88261, params: {‘learning_rate’: 0.01, ‘n_estimators’: 500},
mean: -33663.99313, std: 20179.74172, params: {‘learning_rate’: 0.01, ‘n_estimators’: 1000},
mean: -36502.96591, std: 16225.13167, params: {‘learning_rate’: 0.05, ‘n_estimators’: 50},
mean: -33665.06976, std: 18138.93215, params: {‘learning_rate’: 0.05, ‘n_estimators’: 100},
mean: -34120.16927, std: 20085.98727, params: {‘learning_rate’: 0.05, ‘n_estimators’: 200},
mean: -34177.57983, std: 21188.62796, params: {‘learning_rate’: 0.05, ‘n_estimators’: 500},
mean: -34660.48776, std: 22025.55298, params: {‘learning_rate’: 0.05, ‘n_estimators’: 1000},
mean: -33838.33799, std: 17860.13547, params: {‘learning_rate’: 0.1, ‘n_estimators’: 50},
mean: -33240.66275, std: 18837.11462, params: {‘learning_rate’: 0.1, ‘n_estimators’: 100},
mean: -33181.90461, std: 19910.96435, params: {‘learning_rate’: 0.1, ‘n_estimators’: 200},
mean: -33576.53561, std: 20349.66997, params: {‘learning_rate’: 0.1, ‘n_estimators’: 500},
mean: -34053.72276, std: 20703.38247, params: {‘learning_rate’: 0.1, ‘n_estimators’: 1000},
mean: -35845.98638, std: 21392.95943, params: {‘learning_rate’: 0.2, ‘n_estimators’: 50},
mean: -35973.28358, std: 22094.74565, params: {‘learning_rate’: 0.2, ‘n_estimators’: 100},
mean: -36080.64404, std: 22257.37518, params: {‘learning_rate’: 0.2, ‘n_estimators’: 200},
mean: -36633.99577, std: 22674.09668, params: {‘learning_rate’: 0.2, ‘n_estimators’: 500},
mean: -36964.93338, std: 22742.96590, params: {‘learning_rate’: 0.2, ‘n_estimators’: 1000}],
{‘learning_rate’: 0.1, ‘n_estimators’: 200},
-33181.904612290644)</p>

<h2 id="注意">注意</h2>

<h3 id="调完参数之后有两种方式进行使用xgboost">调完参数之后有两种方式进行使用xgboost</h3>
<p><em>1、直接用接口XGBRegressor，fit之后在预测。好处：快，运行的后的效果还可以</em>     <br />
<em>2、用xgboost先训练，再预测。好处：鲁棒性比较高</em></p>

<h3 id="首先将之前调完的参数设置好">首先将之前调完的参数，设置好</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xgb9</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">booster</span><span class="o">=</span><span class="s">'gbtree'</span><span class="p">,</span>
                    <span class="n">objective</span><span class="o">=</span> <span class="s">'reg:linear'</span><span class="p">,</span>
                    <span class="n">eval_metric</span><span class="o">=</span><span class="s">'rmse'</span><span class="p">,</span>
                    <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">min_child_weight</span><span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
                    <span class="n">max_depth</span><span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                    <span class="n">subsample</span><span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
                    <span class="n">colsample_bytree</span><span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
                    <span class="n">tree_method</span><span class="o">=</span> <span class="s">'exact'</span><span class="p">,</span>
                    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                    <span class="n">nthread</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                    <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">reg_alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>                           
                    <span class="n">seed</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="第一种方案fit之后在predict预测">第一种方案fit之后，在predict预测</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xgb9</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span><span class="n">train_Y</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=0.8, eval_metric='rmse', gamma=0.1,
       learning_rate=0.1, max_delta_step=0, max_depth=5,
       min_child_weight=3, missing=None, n_estimators=200, n_jobs=1,
       nthread=4, objective='reg:linear', random_state=0, reg_alpha=0.05,
       reg_lambda=1, scale_pos_weight=1, seed=27, silent=True,
       subsample=0.8, tree_method='exact')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">xgb9</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">),</span><span class="n">test_Y</span><span class="p">))</span>
</code></pre></div></div>
<p>163.93821478808687</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">13</span><span class="p">))</span>
<span class="n">xgb</span><span class="o">.</span><span class="n">plot_importance</span><span class="p">(</span><span class="n">xgb9</span><span class="p">,</span> <span class="n">max_num_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/images/blog/2018-02-28-xgboost_parameters.png" alt="相关系数" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trainset</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="n">train_Y</span><span class="p">)</span>
<span class="n">testset</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="第二种train完之后在predict">第二种：train完之后在predict</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>

<span class="n">model</span><span class="o">=</span><span class="n">xgb</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">xgb9</span><span class="o">.</span><span class="n">get_params</span><span class="p">(),</span><span class="n">trainset</span><span class="p">,</span><span class="n">num_boost_round</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span><span class="n">evals</span><span class="o">=</span><span class="n">watchlist</span><span class="p">)</span>
</code></pre></div></div>
<p>[0]	train-rmse:494.438
[1]	train-rmse:453.211
[2]	train-rmse:415.193
[3]	train-rmse:381.363
[4]	train-rmse:353.229
…
[9996]	train-rmse:0.43133
[9997]	train-rmse:0.431213
[9998]	train-rmse:0.431125
[9999]	train-rmse:0.431063
CPU times: user 12min 15s, sys: 4.81 s, total: 12min 20s
Wall time: 12min 19s</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_predict</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testset</span><span class="p">)</span>
<span class="n">rmse_test_10</span><span class="o">=</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">test_predict</span><span class="p">,</span><span class="n">test_Y</span><span class="p">))</span>
<span class="n">rmse_test_10</span>
</code></pre></div></div>

<p>168.7448358242037</p>

<p>注意；这里看着第一种方案比第二种方案似乎表现更好一些，但是如果我们拿到线上去测试，会发现第一种方案实际效果差很多。</p>

<h3 id="初步原因">初步原因</h3>
<p>上图树图是fit 下图树图是train，初步观察到：两个图在前三层节点都是一样的，第四和第五层train节点明显比fit要多，更茂密的树应该是鲁棒性(robust)更好一些，这一点应该是初步可以解释train比fit效果更好的原因
关于Grandient Boosting的原理可以参考这篇文章<a href="https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/">Complete Guide to Parameter Tuning in Gradient Boosting (GBM) in Python</a></p>

<p><img src="https://user-images.githubusercontent.com/21167490/36014954-48ec6eea-0da7-11e8-95c8-0b3c0f1d9572.png" alt="xgb_fit_tree" /></p>

<p><img src="https://user-images.githubusercontent.com/21167490/36014967-5400c830-0da7-11e8-8ac5-21b86d03050f.png" alt="xgb_train_tree" /></p>

    </article>
    <div class="share">
      <div class="share-component"></div>
    </div>
    <div class="comment">
      

  

  
        <div id="gitalk-container"></div>
        <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
        <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
        <script>
        var gitalk = new Gitalk({
            id: '/2018/02/28/XGboost_param_share/',
            clientID: '',
            clientSecret: '',
            repo: '',
            owner: '',
            admin: [''],
            labels: ['gitment'],
            perPage: 50,
        })
        gitalk.render('gitalk-container')
        </script>
  


    </div>
  </div>
  <div class="column one-fourth">
    
<h3>Search</h3>
<div id="site_search">
    <input type="text" id="search_box" placeholder="Search">
</div>

<ul id="search_results"></ul>

<link rel="stylesheet" type="text/css" href="http://localhost:4000/assets/css/modules/sidebar-search.css">
<script src="http://localhost:4000/assets/js/jekyll-search.min.js"></script>
<script src="http://localhost:4000/assets/js/search.js"></script>

<script type="text/javascript">
SimpleJekyllSearch({
    searchInput: document.getElementById('search_box'),
    resultsContainer: document.getElementById('search_results'),
    json: 'http://localhost:4000/assets/search_data.json',
    searchResultTemplate: '<li><a href="{url}" title="{desc}">{title}</a></li>',
    noResultsText: 'No results found',
    limit: 10,
    fuzzy: false,
    exclude: ['Welcome']
})
</script>

    

    
<h3 class="post-directory-title mobile-hidden">Table of Contents</h3>
<div id="post-directory-module" class="mobile-hidden">
  <section class="post-directory">
  <!-- Links that trigger the jumping -->
  <!-- Added by javascript below -->
  <dl></dl>
  </section>
</div>

<script src="http://localhost:4000/assets/js/jquery.toc.js"></script>

  </div>
</div>
</section>
<!-- /section.content -->

    <footer class="container">
        <div class="site-footer" role="contentinfo">
            <div class="copyright left mobile-block">
                    © 2015
                    <span title="Hu Wu">Hu Wu</span>
                    <a href="javascript:window.scrollTo(0,0)" class="right mobile-visible">TOP</a>
            </div>

            <ul class="site-footer-links right mobile-hidden">
                <li>
                    <a href="javascript:window.scrollTo(0,0)" >TOP</a>
                </li>
            </ul>
            <a href="http://github.com/wuhuhu800/wuhuhu800.github.io" target="_blank" aria-label="view source code">
                <span class="mega-octicon octicon-mark-github" title="GitHub"></span>
            </a>
            <ul class="site-footer-links mobile-hidden">
                
                <li>
                    <a href="http://localhost:4000/" title="首页" target="">首页</a>
                </li>
                
                <li>
                    <a href="http://localhost:4000/categories/" title="分类" target="">分类</a>
                </li>
                
                <li>
                    <a href="http://localhost:4000/wiki/" title="维基" target="">维基</a>
                </li>
                
                <li>
                    <a href="http://localhost:4000/links/" title="链接" target="">链接</a>
                </li>
                
                <li>
                    <a href="http://localhost:4000/about/" title="关于" target="">关于</a>
                </li>
                
                <li><a href="http://localhost:4000/feed.xml"><span class="octicon octicon-rss" style="color:orange;"></span></a></li>
            </ul>

        </div>
    </footer>
    <!-- / footer -->
    <script src="http://localhost:4000/assets/vendor/share.js/dist/js/share.min.js"></script>
    <script src="http://localhost:4000/assets/js/geopattern.js"></script>
    <script src="http://localhost:4000/assets/js/prism.js"></script>
    <link rel="stylesheet" href="http://localhost:4000/assets/css/globals/prism.css">
    <script>
      jQuery(document).ready(function($) {
        // geopattern
        $('.geopattern').each(function(){
          $(this).geopattern($(this).data('pattern-id'));
        });
       // hljs.initHighlightingOnLoad();
      });
    </script>

    

    

    

    
    <div style="display:none">
      <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-111499340-1', 'auto');
        ga('send', 'pageview');

      </script>
    </div>
    
</body>
</html>
